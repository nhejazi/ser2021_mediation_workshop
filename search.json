[{"path":"index.html","id":"welcome-to-ser","chapter":"Welcome to SER!","heading":"Welcome to SER!","text":"open source, reproducible vignette accompanies half-day workshop \nmodern methods causal mediation analysis, given SER 2021\nMeeting \nMonday, 24 May 2021. encourage use bookdown site, \nconvenience, also made workshop materials available \nPDF.","code":""},{"path":"index.html","id":"about","chapter":"Welcome to SER!","heading":"0.1 About this workshop","text":"Causal mediation analysis can provide mechanistic understanding \nexposure impacts outcome, central goal epidemiology health sciences.\nHowever, rapid methodologic developments coupled formal courses\npresents challenges implementation. Beginning overview classical\ndirect indirect effects, workshop present recent advances \novercome limitations previous methods, allowing : () continuous\nexposures, (ii) multiple, non-independent mediators, (iii) effects\nidentifiable presence intermediate confounders affected exposure.\nEmphasis placed flexible, stochastic interventional direct \nindirect effects, highlighting may applied answer substantive\nepidemiological questions real-world studies. Multiply robust,\nnonparametric estimators causal effects, free open source R\npackages (medshift \nmedoutcon) application, \nintroduced.ensure translation real-world data analysis, workshop \nincorporate hands-R programming exercises allow participants practice \nimplementing statistical tools presented. recommended \nparticipants working knowledge basic notions causal inference,\nincluding counterfactuals identification (linking causal effect \nparameter estimable observed data distribution). Familiarity \nR programming language also recommended.","code":""},{"path":"index.html","id":"schedule","chapter":"Welcome to SER!","heading":"0.2 Workshop schedule","text":"10:00A-10:30A: introductions/mediation set up10:30A-11:00A: estimands choose11:00A-11:30A: discussion: choose real-world examples11:30A-12:00P: shift parameter introduction application lecture part12:00P-12:15P break/discussion12:15P-12:45P estimation natural direct indirect effects,\ninterventional direct indirect effects12:45P-01:15P: practice R code estimation01:15P-01:30P: estimation stochastic interventional direct indirect\neffects01:30P-01:50P: practice: code estimation01:50P-02:00P wrap upNOTE: times listed Pacific Time.","code":""},{"path":"index.html","id":"instructors","chapter":"Welcome to SER!","heading":"0.3 About the instructors","text":"","code":""},{"path":"index.html","id":"iván-díaz","chapter":"Welcome to SER!","heading":"Iván Díaz","text":"Assistant Professor Weill Cornel Medicine. research\nfocuses development non-parametric statistical methods \ncausal inference observational randomized studies \ncomplex datasets, using machine learning. includes \nlimited mediation analysis, methods continuous exposures,\nlongitudinal data including survival analysis, efficiency\nguarantees covariate adjustment randomized trials. also\ninterested general semi-parametric theory, machine learning, \nhigh-dimensional data.","code":""},{"path":"index.html","id":"nima-hejazi","chapter":"Welcome to SER!","heading":"Nima Hejazi","text":"PhD candidate biostatistics UC Berkeley, working joint\ndirection Mark van der Laan Alan Hubbard. research interests fall \nintersection causal inference machine learning, drawing ideas \nnon/semi-parametric estimation large, flexible statistical models develop\nefficient robust statistical procedures evaluating complex target\nestimands observational randomized studies. Particular areas current\nemphasis include causal mediation/path analysis, outcome-dependent sampling\ndesigns, targeted loss-based estimation, applications vaccine efficacy\ntrials. also passionate statistical computing open source\nsoftware development applied statistics.","code":""},{"path":"index.html","id":"kara-rudolph","chapter":"Welcome to SER!","heading":"Kara Rudolph","text":"Assistant Professor Epidemiology Columbia University. research\ninterests developing applying causal inference methods understand\nsocial contextual influences mental health, substance use, violence\ndisadvantaged, urban areas United States. current work focuses \ndeveloping methods transportability mediation, subsequently applying\nmethods understand aspects school peer environments\nmediate relationships neighborhood factors adolescent drug use\nacross populations. generally, work generalizing/ transporting\nfindings study samples target populations identifying subpopulations\nlikely benefit interventions contributes efforts optimally\ntarget available policy program resources.","code":""},{"path":"index.html","id":"repro","chapter":"Welcome to SER!","heading":"0.4 Reproduciblity","text":"workshop materials written using bookdown,\ncomplete source available \nGitHub. version book\nbuilt R version 4.0.5 (2021-03-31), pandoc version r rmarkdown::pandoc_version(), following packages:","code":""},{"path":"index.html","id":"setup","chapter":"Welcome to SER!","heading":"0.5 Setup instructions","text":"","code":""},{"path":"index.html","id":"r-and-rstudio","chapter":"Welcome to SER!","heading":"0.5.1 R and RStudio","text":"R RStudio separate downloads installations. R \nunderlying statistical computing environment. RStudio graphical integrated\ndevelopment environment (IDE) makes using R much easier \ninteractive. need install R install RStudio.","code":""},{"path":"index.html","id":"windows","chapter":"Welcome to SER!","heading":"0.5.1.1 Windows","text":"","code":""},{"path":"index.html","id":"if-you-already-have-r-and-rstudio-installed","chapter":"Welcome to SER!","heading":"0.5.1.1.1 If you already have R and RStudio installed","text":"Open RStudio, click “Help” > “Check updates”. new version \navailable, quit RStudio, download latest version RStudio.check version R using, start RStudio first thing\nappears console indicates version R \nrunning. Alternatively, can type sessionInfo(), also display\nversion R running. Go CRAN\nwebsite check whether \nrecent version available. , please download install . \ncan check \ninformation remove old versions system \nwish .","code":""},{"path":"index.html","id":"if-you-dont-have-r-and-rstudio-installed","chapter":"Welcome to SER!","heading":"0.5.1.1.2 If you don’t have R and RStudio installed","text":"Download R \nCRAN website.Run .exe file just downloadedGo RStudio download\npageUnder Installers select RStudio x.yy.zzz - Windows\nXP/Vista/7/8 (x, y, z represent version numbers)Double click file install itOnce ’s installed, open RStudio make sure works don’t get \nerror messages.","code":""},{"path":"index.html","id":"macos-mac-os-x","chapter":"Welcome to SER!","heading":"0.5.1.2 macOS / Mac OS X","text":"","code":""},{"path":"index.html","id":"if-you-already-have-r-and-rstudio-installed-1","chapter":"Welcome to SER!","heading":"0.5.1.2.1 If you already have R and RStudio installed","text":"Open RStudio, click “Help” > “Check updates”. new version \navailable, quit RStudio, download latest version RStudio.check version R using, start RStudio first thing\nappears terminal indicates version R running.\nAlternatively, can type sessionInfo(), also display \nversion R running. Go CRAN\nwebsite check whether \nrecent version available. , please download install .","code":""},{"path":"index.html","id":"if-you-dont-have-r-and-rstudio-installed-1","chapter":"Welcome to SER!","heading":"0.5.1.2.2 If you don’t have R and RStudio installed","text":"Download R \nCRAN website.Select .pkg file latest R versionDouble click downloaded file install RIt also good idea install XQuartz (needed\npackages)Go RStudio download\npageUnder Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit)\n(x, y, z represent version numbers)Double click file install RStudioOnce ’s installed, open RStudio make sure works don’t get \nerror messages.","code":""},{"path":"index.html","id":"linux","chapter":"Welcome to SER!","heading":"0.5.1.3 Linux","text":"Follow instructions distribution\nCRAN, provide information\nget recent version R common distributions. \ndistributions, use package manager (e.g., Debian/Ubuntu run\nsudo apt-get install r-base, Fedora sudo yum install R), \ndon’t recommend approach versions provided \nusually date. case, make sure least R 3.3.1.Go RStudio download\npageUnder Installers select version matches distribution, \ninstall preferred method (e.g., Debian/Ubuntu sudo dpkg -rstudio-x.yy.zzz-amd64.deb terminal).’s installed, open RStudio make sure works don’t get \nerror messages.setup instructions adapted written Data Carpentry: R\nData Analysis Visualization Ecological\nData.","code":""},{"path":"mediation.html","id":"mediation","chapter":"1 Preliminaries on causal mediation analysis","heading":"1 Preliminaries on causal mediation analysis","text":"","code":""},{"path":"mediation.html","id":"motivating-studies","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.1 Motivating studies","text":"[FILL (KARA?). IDEALLY TWO THREE EXAMPLES CAN\nUSE THROUGHOUT WORKSHOP EFFECTS]","code":""},{"path":"mediation.html","id":"what-is-causal-mediation-analysis","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.2 What is causal mediation analysis?","text":"Like causal analyses, causal mediation analysis different \nstandard statistical mediation analysesStatistical mediation analyses merely assess associations variablesCausal mediation analyses assess system behaves interventionsCausal mediation analysis thus useful understand mechanisms","code":""},{"path":"mediation.html","id":"an-example-of-a-non-causal-mediation-analysis-product-of-coefficients","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.2.1 An example of a non-causal mediation analysis (product of coefficients)","text":"Assume interested effect treatment \\(\\) ([FILL \nMOTIVATING EXAMPLE]) outcome \\(Y\\) ([FILL ]) mediator \\(M\\)\n([FILL ])fit following models:\n\\[\\begin{align}\n    \\E(Y\\mid =) & = \\alpha_0 + \\alpha_1 \\\\\n    \\E(M\\mid =) & = \\gamma_0 + \\gamma_1 \\\\\n    \\E(Y\\mid M=m, =) & = \\beta_0 + \\beta_1 m + \\beta_2 \n  \\end{align}\\]product \\((\\gamma_1\\beta_1)\\) proposed measure effect\n\\(X\\) \\(Y\\) \\(M\\)Causal interpretation problems method:\nhappens confounders relation treatment outcome?\nhappens confounders relation mediataor outcome?\nhappens confounders relation treatment mediator?\nhappens confounders mediator outcome affected treatment?\nhappens confounders relation treatment outcome?happens confounders relation mediataor outcome?happens confounders relation treatment mediator?happens confounders mediator outcome affected treatment?Statistical issues method:\nAssume confounding issue\nCan interpret \\((\\gamma_1\\beta_1)\\) indirect effect?\n: regression models may misspecified\nAssume confounding issueCan interpret \\((\\gamma_1\\beta_1)\\) indirect effect?: regression models may misspecified","code":""},{"path":"mediation.html","id":"causal-mediation-models","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.3 Causal mediation models","text":"workshopp use directed acyclic graphs conceptualize \nconfounding issues. focus two types graph:","code":""},{"path":"mediation.html","id":"no-intermediate-confounders","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.3.1 No intermediate confounders","text":"\nFIGURE 1.1: Directed acylcic graph intermediate confounders mediator-outcome relation affected treatment\n","code":""},{"path":"mediation.html","id":"intermediate-confounders","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.3.2 Intermediate confounders","text":"\nFIGURE 1.2: Directed acylcic graph intermediate confounders mediator-outcome relation affected treatment\ngraphs can interpreted non-parametric structural equation model\n(NPSEM), also known structural causal model (SCM):\\[\\begin{align}\n  W & = f_W(U_W)\\\\\n  & = f_A(W, U_A)\\\\\n  Z & = f_Z(W, , U_Z)\\\\\n  M & = f_M(W, , Z, U_M)\\\\\n  Y & = f_Y(W, , Z, M, U_Y)\n\\end{align}\\]\\(U=(U_W, U_A, U_Z, U_M, U_Y)\\) vector unmeasured exogenous\nfactors affecting systemThe functions \\(f\\) assumed fixed unknownWe posit model system equation nature uses geenrate \ndata handTherefore leave functions \\(f\\) unspecified (.e., know \ntrue nature mechanisms)Sometimes know something: e.g., \\(\\) randomized know \\(=f_A(U_A)\\)\n\\(U_A\\) independent everything.","code":""},{"path":"mediation.html","id":"counterfactuals","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.4 Counterfactuals","text":"define effects interest using counterfactualsCounterfactuals hypothetical random variables \nobserved world able perform interventions \nrandom variables interest\\(Y_a\\) counterfactual variable hypothetical world \\(\\P(=)=1\\)\nprobability one\\(Y_{,m}\\) counterfactual outcome world \\(\\P(=,M=m)=1\\)\\(M_a\\) counterfactual variable representing mediator world\n\\(\\P(=)=1\\).","code":""},{"path":"mediation.html","id":"how-are-counterfactuals-defined","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.4.1 How are counterfactuals defined?","text":"can use counterfactual variables primitivesIn NPSEM framework, counterfactuals quantities derived \nmodel:\n\\[\\begin{align}\n  Y_a  &= f_Y(W, , Z, M, U_Y)\\\\\n  Y_{,m}  &= f_Y(W, , Z, m, U_Y)\\\\\n  M_a  &= f_M(W, , Z, U_M)\n\\end{align}\\]can also define nested counterfactualsFor example, \\(\\) binary, can think following counterfactual\n\\[\\begin{equation*}\n  Y_{1, M_0} = f_Y(W, 1, Z, M_0, U_Y)\n\\end{equation*}\\]Interpreted outcome individual hypothetical world \ntreatment given mediator held value \ntaken treatment","code":""},{"path":"estimands.html","id":"estimands","chapter":"2 Path-specific casual mediation effect types","heading":"2 Path-specific casual mediation effect types","text":"Controlled direct effectsNatural direct indirect effectsInterventional direct indirect effects","code":""},{"path":"estimands.html","id":"controlled-direct-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.1 Controlled direct effects","text":"\\[\\psi_{\\text{CDE}} = \\E(Y_{1,m} - Y_{0,m}) \\]Set \\(M=m\\) uniformly everyone populationCompare \\(=1\\) vs \\(=0\\) \\(M=m\\) fixed","code":""},{"path":"estimands.html","id":"identification-assumptions","chapter":"2 Path-specific casual mediation effect types","heading":"2.1.1 Identification assumptions:","text":"Confounder assumptions:\n\\(\\indep Y_{,m} \\mid W\\)\n\\(M \\indep Y_{,m} \\mid W, , Z\\)\n\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, , Z\\)Positivity assumptions:\n\\(\\P(M = m \\mid Z, =, W) > 0 \\text{  } .e.\\)\n\\(\\P(=\\mid W) > 0 \\text{  } .e.\\)\n\\(\\P(M = m \\mid Z, =, W) > 0 \\text{  } .e.\\)\\(\\P(=\\mid W) > 0 \\text{  } .e.\\)","code":""},{"path":"estimands.html","id":"is-this-the-estimand-i-want","chapter":"2 Path-specific casual mediation effect types","heading":"2.1.2 Is this the estimand I want?","text":"Makes sense can intervene directly \\(M\\)\ncan think policy set everyone single constant\nlevel \\(m \\\\mathcal{M}\\).\nJ. Pearl calls prescriptive.\nCan think example?\nAir pollution, rescue inhaler dosage, hospital visits\nprovide decomposition average treatment effect direct indirect effects\ncan think policy set everyone single constant\nlevel \\(m \\\\mathcal{M}\\).J. Pearl calls prescriptive.Can think example?Air pollution, rescue inhaler dosage, hospital visitsDoes provide decomposition average treatment effect direct indirect effectsWhat research question doesn’t involve intervening directly \nmediator?want decompose average treatment effect direct \nindirect counterparts?","code":""},{"path":"estimands.html","id":"natural-direct-and-indirect-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.2 Natural direct and indirect effects","text":"Natural direct effect (NDE):\n\\[\\begin{equation*}\n  \\psi_{\\text{NDE}} = \\E(Y_{1,M_0} - Y_{0,M_0})\n\\end{equation*}\\]Natural indirect effect (NIE):\n\\[\\begin{equation*}\n  \\psi_{\\text{NIE}} = \\E(Y_{1,M_1} - Y_{1,M_0})\n\\end{equation*}\\]NDE can also written : \\(\\E_W \\sum_m \\{\\E(Y_{1,m} \\mid W) - \\E(Y_{0,m} \\mid W)\\} \\P(M_{0}=m \\mid W)\\)Weighted average controlled direct effects level \\(m\\).\ninteraction \\(\\) \\(M\\) \\(Y\\), CDE = NDE.","code":""},{"path":"estimands.html","id":"identification-assumptions-1","chapter":"2 Path-specific casual mediation effect types","heading":"2.2.1 Identification assumptions:","text":"\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, \\)\\(\\indep M_a \\mid W\\)\\(M_0 \\indep Y_{1,m} \\mid W\\)positivity assumptions\n\\(M_0 \\indep Y_{1,m} \\mid W\\) mean?Conditional \\(W\\), knowledge \\(M\\) absence treatment \\(\\)\nprovides information effect \\(\\) \\(Y\\).Can think data-generating mechanism violate \nassumption?Whenever believe treatment assignment works adherence (.e., almost\nalways), violating assumption.","code":""},{"path":"estimands.html","id":"is-this-the-estimand-i-want-1","chapter":"2 Path-specific casual mediation effect types","heading":"2.2.2 Is this the estimand I want?","text":"Makes sense intervene \\(\\) directly \\(M\\).Want understand natural mechanism underlying association/ total\neffect. J. Pearl calls descriptive.NDE + NIE = total effect (ATE).Okay assumptions.\ndata structure involves post-treatment confounder \nmediator-outcome relationship (e.g., adherence)?\nFIGURE 1.2: Directed acylcic graph intermediate confounders mediator-outcome relation affected treatment\n","code":""},{"path":"estimands.html","id":"interventional-indirect-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.3 Interventional (in)direct effects","text":"Fully conditional pastConditional SDE: \\(\\E(Y_{, g_{M \\mid Z, ^{\\star}, W}}) - \\E(Y_{^{\\star}, g_{M \\mid Z, ^{\\star}, W}})\\)Conditional SIE: \\(\\E(Y_{, g_{M \\mid Z, , W}}) - \\E(Y_{, g_{M \\mid Z, ^{\\star}, W}})\\)Marginal SDE: \\(\\E(Y_{, g_{M \\mid ^{\\star}, W}}) - \\E(Y_{^{\\star}, g_{M \\mid ^{\\star}, W}})\\)Marginal SIE: \\(\\E(Y_{, g_{M \\mid , W}}) - \\E(Y_{, g_{M \\mid ^{\\star}, W}})\\)Note \\(g_{M \\mid Z, ^{\\star}, W}\\), \\(g_{M \\mid ^{\\star}, W}\\) represents\nstochastic intervention mediator, value \\(m\\) drawn \nprobability \\(\\P(M = m \\mid Z, = ^{\\star}, W = w)\\),\n\\(\\P(M = m \\mid = ^{\\star}, W = w)\\), respectivelyCan think example want conditional versions?\nMarginal versions?","code":""},{"path":"estimands.html","id":"identification-assumptions-2","chapter":"2 Path-specific casual mediation effect types","heading":"2.3.1 Identification assumptions:","text":"\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, \\)\\(\\indep M_a \\mid W\\)positivity assumptions.estimand want?Makes sense intervene \\(\\) directly \\(M\\).Goal understand natural mechanism underlying association total\neffect.Okay assumptions!","code":""},{"path":"estimands.html","id":"estimand-summary","chapter":"2 Path-specific casual mediation effect types","heading":"2.4 Estimand Summary","text":"","code":""},{"path":"estimands.html","id":"interventional","chapter":"2 Path-specific casual mediation effect types","heading":"2.5 The Interventional Direct and Indirect Effects","text":"","code":""},{"path":"estimands.html","id":"definition-of-the-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.5.1 Definition of the effects","text":"Consider following directed acyclic graph.\nFIGURE 2.1: Directed acylcic graph intermediate confounders mediator-outcome relation affected treatment\n, \\(\\) treatment interest, \\(M\\) mediator \ninterest, \\(W\\) pre-treatment variable containing confounders \n\\(\\) \\(M\\) \\(Y\\),\\(Z\\) post-treatment variable contaning\nconfounders mediator exposure affected \ntreatment.","code":""},{"path":"estimands.html","id":"example","chapter":"2 Path-specific casual mediation effect types","heading":"2.5.2 Example","text":"[FILL ]","code":""},{"path":"estimands.html","id":"unidentifiability-of-the-nde-and-nie-in-this-setting","chapter":"2 Path-specific casual mediation effect types","heading":"2.5.3 Unidentifiability of the NDE and NIE in this setting","text":"example, natural direct indirect effects \nunidentifiable observed data \\((W,,Z,M,Y)\\). technical\nreason cross-world counterfactual assumption\n\\[\\begin{equation*}\n  Y(1,m)\\indep M(0)\\mid W\n\\end{equation*}\\]hold aboce directed acyiclic graph. Intuitively, \nreason intervention setting \\(=1\\) (necessary \ndefinition \\(Y(1,m)\\)) induces counterfactual variable\n\\(Z(1)\\). Likewise, intervention setting \\(=0\\) (necessary \ndefinition \\(M(0)\\)) induces counterfactual \\(Z(0)\\). variables\n\\(Z(1)\\) \\(Z(0)\\) correlated share unmeasured common\ncauses. variable \\(Z(1)\\) correlated \\(Y(1,m)\\), \nvariable \\(Z(0)\\) correlated \\(M(0)\\), \ncounterfactual outcomes hypothetical worlds. Thus, \nachieve \\(Y(1,m)\\) independent \\(M(0)\\), necessary \nadjust either \\(Z(1)\\) \\(Z(0)\\). impossible since\nvariables unmeasured.","code":""},{"path":"estimands.html","id":"recovering-direct-and-indirect-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.5.4 Recovering direct and indirect effects","text":"Even though estimation NDE NIE possible \napresence confounders mediation-outcome relation affected \ntreatment, possible redefine effects way \nidentifiable. Specifically:Let \\(G()\\) denote random draw distribution \\(M() \\mid W\\)Define counterfactual \\(Y(1,G(0))\\) counterfactual\nvariable hypothetical world \\(\\) set \\(=1\\) \\(M\\) \nset \\(M=G(0)\\) porbability one.Define \\(Y(0,G(0))\\) \\(Y(1,G(1))\\) similarlyThen can define:\n\\[\\begin{equation*}\n  \\E[Y(1,G(1)) - Y(0,G(0))] = \\underbrace{\\E[Y(1,G(1)) -\n    Y(1,G(0))]}_{\\text{interventional indirect effect}} +\n    \\underbrace{\\E[Y(1,G(0)) -\n    Y(0,G(0))]}_{\\text{interventional direct effect}}\n\\end{equation*}\\]","code":""},{"path":"estimandirl.html","id":"estimandirl","chapter":"3 How to choose an estimand: Real world example","heading":"3 How to choose an estimand: Real world example","text":"","code":""},{"path":"estimandirl.html","id":"comparative-effectivness-of-two-medications-for-opioid-use-disorder-oud","chapter":"3 How to choose an estimand: Real world example","heading":"3.1 Comparative effectivness of two medications for opioid use disorder (OUD)","text":"Motivation: Opposite overall treatment effects homeless versus\nnonhomeless participants.","code":""},{"path":"estimandirl.html","id":"getting-specific-about-the-question","chapter":"3 How to choose an estimand: Real world example","heading":"3.1.1 Getting specific about the question","text":"extent indirect effect mediators adherence, pain, \ndepressive symptoms explain differences treatment effects OUD relapse\nhomeless nonhomeless individuals?estimand want?Can set \\(M=m\\) (.e., value) everyone?interested estimating indirect effects?\\(\\rightarrow\\) , controlled direct effect.intermediate confounder?Yes, ’s important.\\(\\rightarrow\\) , natural ()direct effects., ’re left interventional direct indirect effects.want estimate path treatment initiation (\\(Z\\))?Yes, , conditional versions effects.Estimands:\nDirect effect: \\(\\E(Y_{1,g_0} - Y_{0,g_0})\\)\nIndirect effect: \\(\\E(Y_{1,g_1} - Y_{1,g_0})\\)\nDirect effect: \\(\\E(Y_{1,g_0} - Y_{0,g_0})\\)Indirect effect: \\(\\E(Y_{1,g_1} - Y_{1,g_0})\\)Need incorporate multiple continuous mediators","code":""},{"path":"stochastic.html","id":"stochastic","chapter":"4 Stochastic Direct and Indirect Effects","heading":"4 Stochastic Direct and Indirect Effects","text":"","code":""},{"path":"stochastic.html","id":"definition-of-the-effects-1","chapter":"4 Stochastic Direct and Indirect Effects","heading":"4.1 Definition of the effects","text":"Consider following directed acyclic graph.\nFIGURE 1.1: Directed acylcic graph intermediate confounders mediator-outcome relation affected treatment\n","code":""},{"path":"stochastic.html","id":"motivation-for-stochastic-interventions","chapter":"4 Stochastic Direct and Indirect Effects","heading":"4.2 Motivation for stochastic interventions","text":"far discussed controlled, natural, interventional ()direct effectsThese effects require \\(0 < \\P(=1\\mid W) < 1\\)defined binary exposuresWhat can positivity assumption hold exposure\ncontinuous?Solution: can use stochastic effects","code":""},{"path":"stochastic.html","id":"definition-of-stochastic-effects","chapter":"4 Stochastic Direct and Indirect Effects","heading":"4.3 Definition of stochastic effects","text":"two possible ways defining stochastic effects:Consider effect intervention exposure drawn \ndistribution\nExample: [FILL ]\nExample: [FILL ]Consider effect intervention post-intervention exposure \nfunction actually received exposure\nExample: [FILL ]\nExample: [FILL ]cases \\(\\mid W\\) non-deterministic, thus name stochastic intervention","code":""},{"path":"stochastic.html","id":"example-incremental-propensity-score-interventions-ipsi-kennedy2018nonparametric","chapter":"4 Stochastic Direct and Indirect Effects","heading":"Example: incremental propensity score interventions (IPSI) (Kennedy 2018)","text":"","code":""},{"path":"stochastic.html","id":"definition-of-the-intervention","chapter":"4 Stochastic Direct and Indirect Effects","heading":"Definition of the intervention","text":"Assume \\(\\) binary, \\(\\P(=1\\mid W=w) = g(1\\mid w)\\) propensity scoreConsider intervention individual receives intervention\nprobability \\(g_\\delta(1\\mid w)\\), equal \n\\[\\begin{equation*}\n  g_\\delta(1\\mid w)=\\frac{\\delta g(1\\mid w)}{\\delta g(1\\mid w) +\n  1 - g(1\\mid w)}\n\\end{equation*}\\]e.g., draw post-intervention exposure Bernoulli variable \nprobability \\(g_\\delta(1\\mid w)\\)value \\(\\delta\\) user givenLet \\(A_\\delta\\) denote post-intervention distributionSome algebra shows \\(\\delta\\) odds ratio comparing pre- \npost-intervantion distributions\n\\[\\begin{equation*}\n  \\delta = \\frac{\\text{odds}(A_\\delta = 1\\mid W=w)}\n  {\\text{odds}(= 1\\mid W=w)}\n\\end{equation*}\\]gives intervention nice interpretation happen \nworld odds receiving treatment increased \\(\\delta\\)Let \\(Y_{A_\\delta}\\) denote outcome hypothetical world","code":""},{"path":"stochastic.html","id":"example-modified-treatment-policies","chapter":"4 Stochastic Direct and Indirect Effects","heading":"4.3.1 Example: modified treatment policies","text":"","code":""},{"path":"stochastic.html","id":"definition-of-the-intervention-1","chapter":"4 Stochastic Direct and Indirect Effects","heading":"Definition of the intervention","text":"","code":""},{"path":"stochastic.html","id":"mediation-analysis-for-stochastic-interventions","chapter":"4 Stochastic Direct and Indirect Effects","heading":"4.3.2 Mediation analysis for stochastic interventions","text":"total effect IPSI can computed contrast outcome \nintervention vs intervention:\n\\[\\begin{equation*}\n  \\psi = \\E[Y_{A_\\delta} - Y]\n\\end{equation*}\\]Recall NPSEM\n\\[\\begin{align}\n  W & = f_W(U_W)\\\\\n  & = f_A(W, U_A)\\\\\n  M & = f_M(W, , U_M)\\\\\n  Y & = f_Y(W, , M, U_Y)\n\\end{align}\\]\\(Y_{A_\\delta} = f_Y(W, A_\\delta, M_{A_\\delta}, U_Y)\\)Thus, \\(Y_{A_\\delta} = Y_{A_\\delta, M_{A_\\delta}}\\) \\(Y = Y(,M())\\)Let us introduce counterfactual \\(Y_{A_\\delta,M}\\), interpreted \noutcome observed world intervention \\(\\) performed \nmediator fixed value taken interventionThen can decompose total effect :\n\\[\\begin{align*}\n  \\E[Y&_{A_\\delta,M_{A_\\delta}} - Y_{,M_A}] = \\\\\n  &\\underbrace{\\E[Y_{A_\\delta,M_{A_\\delta}} -\n    Y_{A_\\delta,M_A}]}_{\\text{stochastic natural indirect effect}} +\n    \\underbrace{\\E[Y_{,M_{A_\\delta}} -\n    Y_{,M_A}]}_{\\text{stochastic natural direct effect}}\n\\end{align*}\\]","code":""},{"path":"stochastic.html","id":"identification-of-the-effect-of-a-stochastic-intervention","chapter":"4 Stochastic Direct and Indirect Effects","heading":"4.4 Identification of the effect of a stochastic intervention","text":"","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"preliminaries-on-semiparametric-estimation","chapter":"5 Preliminaries on semiparametric estimation","heading":"5 Preliminaries on semiparametric estimation","text":"","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"why-do-we-need-new-estimation-tools","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1 Why do we need new estimation tools?","text":"seen mediation parameters consider can \nseen function joint probability distribution \\(O=(W,,Z,M,Y)\\)seen mediation parameters consider can \nseen function joint probability distribution \\(O=(W,,Z,M,Y)\\)example, identifiability assumptions natural direct effect \nequal \n\\[\\begin{equation*}\n  \\psi(\\P) =  \\sum_{m,w}\\big[\\E(Y\\mid =1,M=m,W=w) -\n    \\E(Y\\mid =0,M=m,W=w)\\big]\\P(M=m\\mid =0, W=w)\\P(W=w)\n\\end{equation*}\\]example, identifiability assumptions natural direct effect \nequal \n\\[\\begin{equation*}\n  \\psi(\\P) =  \\sum_{m,w}\\big[\\E(Y\\mid =1,M=m,W=w) -\n    \\E(Y\\mid =0,M=m,W=w)\\big]\\P(M=m\\mid =0, W=w)\\P(W=w)\n\\end{equation*}\\]notation \\(\\psi(\\P)\\) implies parameter function \\(\\P\\)notation \\(\\psi(\\P)\\) implies parameter function \\(\\P\\)means can compute distribution \\(\\P\\)means can compute distribution \\(\\P\\)example, know true \\(\\P(W,,M,Y)\\), can comnpute true value\nparameter :\nComputing conditional expectation \\(\\E(Y\\mid =1,M=m,W=w)\\) values\n\\((m,w)\\)\nComputing probability \\(\\P(M=m\\mid =0,W=w)\\) values \\((m,w)\\)\nComputing probability \\(\\P(W=w)\\) values \\(w\\)\nComputing sum values \\((m,w)\\)\nexample, know true \\(\\P(W,,M,Y)\\), can comnpute true value\nparameter :Computing conditional expectation \\(\\E(Y\\mid =1,M=m,W=w)\\) values\n\\((m,w)\\)Computing probability \\(\\P(M=m\\mid =0,W=w)\\) values \\((m,w)\\)Computing probability \\(\\P(W=w)\\) values \\(w\\)Computing sum values \\((m,w)\\)compute true value knew true\ndistribution \\(\\P\\)compute true value knew true\ndistribution \\(\\P\\)can use logic estimation:\nFit regression estimate \\(\\E(Y\\mid =1,M=m,W=w)\\)\nFit regression estimate \\(\\P(M=m\\mid =0,W=w)\\)\nEstimate \\(\\P(W=w)\\) empirical distribution\ncan use logic estimation:Fit regression estimate \\(\\E(Y\\mid =1,M=m,W=w)\\)Fit regression estimate \\(\\P(M=m\\mid =0,W=w)\\)Estimate \\(\\P(W=w)\\) empirical distributionThis known g-computation estimator (estimator later)known g-computation estimator (estimator later)","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"how-can-g-estimation-be-implemented-in-practice","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.1 How can g-estimation be implemented in practice?","text":"two possible ways g-computation estimation:\nUsing parametric models regressions\nUsing flexible data-adaptive regression (aka machine learning)\nUsing parametric models regressionsUsing flexible data-adaptive regression (aka machine learning)","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"pros-and-cons-of-parametric-models","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.2 Pros and cons of parametric models","text":"Pros:\nEasy understand\nEase implementation (standard regression software)\nCan use Delta method bootstrap computation standard errors\nEasy understandEase implementation (standard regression software)Can use Delta method bootstrap computation standard errorsCons:\nUnless \\(W\\) \\(M\\) contain categorical variables, easy\nmisspecify models\ncan introduce sizable bias estimators\nbias highly problematic\ngo thorough process correctly specify causal models \navoid bias\nOverly simplisitc models introduce bias squander efforts\nbias can small large can never know single data\nanalysis\n\nUnless \\(W\\) \\(M\\) contain categorical variables, easy\nmisspecify modelsThis can introduce sizable bias estimatorsThis bias highly problematic\ngo thorough process correctly specify causal models \navoid bias\nOverly simplisitc models introduce bias squander efforts\nbias can small large can never know single data\nanalysis\ngo thorough process correctly specify causal models \navoid biasOverly simplisitc models introduce bias squander effortsThe bias can small large can never know single data\nanalysis","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"pros-and-cons-of-g-computation-with-data-adaptive-regression","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.3 Pros and cons of g-computation with data-adaptive regression","text":"Pros:\nEasy understand\nAlleviate model-misspecification bias\nEasy understandAlleviate model-misspecification biasCons:\nMight harder implement depending regression procedure\ngeneral approaches computation standard errors confidence\nintervals\nMight harder implement depending regression procedureNo general approaches computation standard errors confidence\nintervals","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"semiparametric-estimation---an-alternative-to-solve-these-problems","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.2 Semiparametric estimation - an alternative to solve these problems","text":"","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"biasvariance-tradeoff","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.2.1 Bias/variance tradeoff","text":"lot recent literature causal inference data-adaptive\nregression uses following ideasA lot recent literature causal inference data-adaptive\nregression uses following ideasG-computation estimation data-adaptive regression offers incorrect\nbias/variance trade-offG-computation estimation data-adaptive regression offers incorrect\nbias/variance trade-offSpecifically, bias g-computation estimator can often expressed \n\\[\\begin{equation*}\n  \\psi(\\hat\\P) - \\psi(\\P) \\approx -\\E[D(O;\\hat\\P)]\n\\end{equation*}\\]Specifically, bias g-computation estimator can often expressed \n\\[\\begin{equation*}\n  \\psi(\\hat\\P) - \\psi(\\P) \\approx -\\E[D(O;\\hat\\P)]\n\\end{equation*}\\]function \\(D(O;\\P)\\) called efficient influence function (EIF)function \\(D(O;\\P)\\) called efficient influence function (EIF)EIF must found case--case basis parameter \\(\\psi(\\P)\\)EIF must found case--case basis parameter \\(\\psi(\\P)\\)example, estimating standardized mean \\(\\psi(P)=\\E[\\E(Y\\mid =1, W)]\\), \n\\[\\begin{equation*}\n  D(O,\\hat\\P) = \\frac{}{\\hat P(=1\\mid W)}[Y - \\hat\\E(Y\\mid =1, W)] +\n  \\hat\\E(Y\\mid =1, W) - \\psi(\\hat\\P)\n\\end{equation*}\\]example, estimating standardized mean \\(\\psi(P)=\\E[\\E(Y\\mid =1, W)]\\), \n\\[\\begin{equation*}\n  D(O,\\hat\\P) = \\frac{}{\\hat P(=1\\mid W)}[Y - \\hat\\E(Y\\mid =1, W)] +\n  \\hat\\E(Y\\mid =1, W) - \\psi(\\hat\\P)\n\\end{equation*}\\]workshop present specific form \\(D(O;\\hat\\P)\\) \nparameters useIn workshop present specific form \\(D(O;\\hat\\P)\\) \nparameters useBut estimators discuss implement packages based \ntheser EIFsBut estimators discuss implement packages based \ntheser EIFs","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"bias-correction-of-g-computation-estimators","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.2.2 Bias-correction of g-computation estimators","text":"least two ways use EIF perform bias correction \ng-computation estimatorThe first one -called one step estimator:\n\\[\\begin{equation*}\n  \\psi(\\hat \\P) + \\frac{1}{n}\\sum_{=1}^n D(O;\\hat \\P_i)\n\\end{equation*}\\]idea behind one-step estimator simple: subtract estimate \nbias g-computation estimatorThe second approach targeted maximum likelihood estimator (TMLE)TMLE based principle possile construct \ndata-adaptive estimator \\(\\tilde \\P\\) \n\\[\\begin{equation*}\n  \\frac{1}{n}\\sum_{=1}^n D(O;\\tilde \\P_i)=0\n\\end{equation*}\\]Thus, special data-adaptive estimate \\(\\tilde \\P\\), TMLE \nactually just g-computation estimator \\(\\psi(\\tilde\\P)\\)","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"estimating-natural-and-interventional-effects","chapter":"6 Estimating natural and interventional effects","heading":"6 Estimating natural and interventional effects","text":"","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"natural-indirect-effects","chapter":"6 Estimating natural and interventional effects","heading":"6.1 Natural (in)direct effects","text":"Recall:\nFIGURE 1.1: Directed acylcic graph intermediate confounders mediator-outcome relation affected treatment\nAssuming binary \\(\\), define natural direct effect :\n\\[NDE = E(Y_{1,M_{0}} - Y_{0,M_{0}})\\],natural indirect effect :\n\\[NIE = E(Y_{1,M_{1}} - Y_{1,M_{0}})\\].","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"simple-case-for-intuition","chapter":"6 Estimating natural and interventional effects","heading":"6.1.1 Simple case for intuition","text":"observed data \\(O=(W, , M, Y)\\)SCM represented DAG following causal models:\n\\[\\begin{align*}\n  W & = f_W(U_W)\\\\\n  & = f_A(W, U_A)\\\\\n  M & = f_M(W, , U_M)\\\\\n  Y & = f_Y(W, , M, U_Y),\n\\end{align*}\\]\n\\((U_W, U_A,U_M, U_Y)\\) exogenous random errors.assume\n- \\(\\) single binary randomized treatment (thus \\(= f_A(U_A)\\))\n- \\(M\\) single binary mediator\n- restrictions distribution \\(W\\) \\(Y\\)Recall need assume following identify caual effects\nobserved data:\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, \\)\\(\\indep M_a \\mid W\\)\\(M_0 \\indep Y_{1,m} \\mid W\\)positivity assumptions","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"how-to-estimate-using-g-computation","chapter":"6 Estimating natural and interventional effects","heading":"6.1.2 How to estimate using G-computation","text":"Let’s take NDE example:Fit regression \\(Y\\) \\(M,,W\\). Predict outcome values setting \\(=1\\).\n’ll call result \\(\\bar{Q}_Y(M,1,W)\\). Predict outcome values setting\n\\(=0\\). ’ll call result \\(\\bar{Q}_Y(M,0,W)\\).Take difference \\(\\bar{Q}_Y(M,1,W) - \\bar{Q}_Y(M,0,W)\\) regress \n\\(W\\) among \\(=0\\). recovers expected difference \nindividuals set control condition \\(= 0\\).sample mean predicted values gives estimate.","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"how-to-estimate-using-the-doubly-robust-methods-that-rely-on-the-eif","chapter":"6 Estimating natural and interventional effects","heading":"6.1.3 How to estimate using the doubly robust methods that rely on the EIF","text":"EIC NDE (\\(\\Psi_{NDE}\\)) given :\\[\\begin{align}\n    D^{\\star} &= \\bigg\\{ \\frac{(=1)}{g(1|W)}\\frac{Q(M|W,0)}{Q(M|W,1)} -\n      \\frac{(=0)}{g(0|W)}\\bigg\\} \\times (Y-\\bar{Q}_Y(M,,W))  \\\\\n    &+ \\frac{(=0)}{g(0|W)}\\{ \\bar{Q}_{diff} - E(\\bar{Q}_{diff} | W,0) \\}\\\\\n    &+ E(\\bar{Q}_{diff} | W,0) - \\Psi_{NDE}\n\\end{align}\\]","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"how-to-estimate-using-tmle","chapter":"6 Estimating natural and interventional effects","heading":"6.1.4 How to estimate using TMLE","text":"Estimate\n\\[\\begin{equation*}\n C_Y(Q_M, g)(O) = \\Bigg\\{\\frac{\\(= 1)}{g(1 \\mid W)}\n   \\frac{Q_M(M \\mid 0, W)}{Q_M(M \\mid 1, W)} -\n   \\frac{\\(= 0)}{g(0 \\mid W)} \\Bigg\\}.\n  \\end{equation*}\\]\nBreaking , \\(\\frac{\\(= 1)}{g(1 \\mid W)}\\) inverse probability\nweight \\(= 1\\) , likewise, \\(\\frac{\\(= 0)}{g(0 \\mid W)}\\) inverse\nprobability weight \\(= 0\\). middle term ratio mediator\ndensity \\(= 0\\) mediator density \\(= 1\\).Estimating \\(Q_M\\) really hard problem \\(M\\) high-dimensional. ,\nsince ratio conditional densitities, can reparamterize\nusing Bayes rule get something easier compute:\n\\[\\begin{equation*}\n  \\frac{\\P(= 0 \\mid M, W) g(0 \\mid W)}{\\P(= 1 \\mid M, W) g(1 \\mid W)}.\n\\end{equation*}\\]Underneath hood, counterfactual outcome difference\n\\(\\bar{Q}_{\\text{diff}}\\) \\(P(\\mid Z, W)\\), conditional probability \\(\\)\ngiven \\(Z\\) \\(W\\), used constructing auxiliary covariate TML\nestimation. nuisance parameters play important role \nbias-correcting TMLE-update step.estimate \\(g_{\\mid W}(W)=P(=\\mid W)\\) logistic regression \n\\(\\) \\(W\\), generating predicted probabilities \\(=1\\) \\(g(1 \\mid W)\\)\n\\(=0\\) \\(g(0 \\mid W)\\).estimate \\(\\P(=\\mid M, W)\\) logistic regression \\(\\) \\(M, W\\),\ngenerating predicted probabilities \\(=1\\) \\(=0\\).\\(\\bar{Q}_Y(M,^\\prime,W) - \\bar{Q}_Y(M,^\\star,W)\\)obtain estimate \\(\\bar{Q}_{diff} = \\bar{Q}_Y(M,1,W) - \\bar{Q}_Y(M,0,W)\\), predict values \\(Y\\) regression \\(Y\\) \\(M,,W\\),\nsetting \\(=1\\) \\(=0\\), giving \\(\\hat{Y}(m, 1, w)\\) \\(\\hat{Y}(m, 1, w)\\).Estimate \\(\\hat{\\epsilon}\\) setting \\(\\epsilon\\) intercept \nweighted logistic regression model \\(Y\\) \n\\(logit(\\hat{\\bar{Q}}_{Y}(M,,W))\\) offset weights \\(\\hat{C}_{Y}\\).Estimate \\(\\hat{\\epsilon}\\) setting \\(\\epsilon\\) intercept \nweighted logistic regression model \\(Y\\) \n\\(logit(\\hat{\\bar{Q}}_{Y}(M,,W))\\) offset weights \\(\\hat{C}_{Y}\\).estimates \\(\\bar{Q}_{Y}(M,1,W)\\) \\(\\bar{Q}_{Y}(M,0,W)\\) updated\n\\(\\hat{\\bar{Q}}^{\\star}_{Y}(M,,W) = \\hat{\\bar{Q}}_{Y}(\\epsilon_n)(M,,W)\\). gives updated difference:\n\\(\\hat{\\bar{Q}}^{\\star}_{diff}(M,,W)\\).estimates \\(\\bar{Q}_{Y}(M,1,W)\\) \\(\\bar{Q}_{Y}(M,0,W)\\) updated\n\\(\\hat{\\bar{Q}}^{\\star}_{Y}(M,,W) = \\hat{\\bar{Q}}_{Y}(\\epsilon_n)(M,,W)\\). gives updated difference:\n\\(\\hat{\\bar{Q}}^{\\star}_{diff}(M,,W)\\).regress \\(\\hat{\\bar{Q}}^{\\star}_{diff}(M,,W)\\) \\(W\\) among \n\\(=0\\). Taking empirical mean predicted values gives us \nTML estimate NDE.","code":"\namodel <- \"a ~ w \"\nmmodel <- \"m ~ a + w\"\namodel <- \"a ~ m + w\"\nymodel <- \"y ~ m + a*w\"\n\n# make gm\nafit <- glm(formula = amodel, family = \"binomial\", data = obsdat)\nmfit <- glm(formula = mmodel, family = \"binomial\", data = obsdat)\n\na1 <- predict(afit, newdata = data.frame(w = obsdat$w), type = \"response\")\na0 <- 1 - a1\n\nam1 <- predict(amfit,\n  newdata = data.frame(w = obsdat$w, m = obsdat$m),\n  type = \"response\"\n)\nam0 <- 1 - am1\ncy <- (am0 * a0) / (am1 * a1)\nqyinit <- cbind(\n  predict(glm(\n    formula = ymodel, family = \"binomial\",\n    data = data.frame(cbind(datw, a = a, m = m, y = y))\n  ),\n  newdata = data.frame(cbind(datw, a, m)), type = \"response\"\n  ),\n  predict(glm(\n    formula = ymodel, family = \"binomial\",\n    data = data.frame(cbind(datw, a = a, m = m, y = y))\n  ),\n  newdata = data.frame(cbind(datw, a = 0, m)), type = \"response\"\n  ),\n  predict(glm(\n    formula = ymodel, family = \"binomial\",\n    data = data.frame(cbind(datw, z = z, m = m, y = y))\n  ),\n  newdata = data.frame(cbind(datw, a = 1, m)), type = \"response\"\n  )\n)\n\nqbardiff <- qyinit[, 3] - qyinit[, 2]\nepsilon <- coef(glm(y ~ 1,\n  weights = cy, offset = (qlogis(qyinit[, 1])),\n  family = \"quasibinomial\"\n))\nqyupa0 <- plogis(qlogis(qyinit[, 2]) + epsilon)\nqyupa1 <- plogis(qlogis(qyinit[, 3]) + epsilon)\nqdiffup <- qyupa1 - qyupa0\nmargqdiff_fit <- glm(qdiffup ~ w,\n  data = data.frame(\n    qdiffup = qdiffup[a == 0],\n    w = w[a == 0]\n  )\n)\nmargqdiff <- predict(margqdiff_fit,\n  newdata = data.frame(qdiffup = qdiffup, w = w)\n)\ntmlende <- mean(margqdiff)"},{"path":"estimating-natural-and-interventional-effects.html","id":"interventional-direct-and-indirect-effects","chapter":"6 Estimating natural and interventional effects","heading":"6.2 Interventional direct and indirect effects","text":"Recall presence intermediate confounder natural ()direct effects identified\nFIGURE 2.1: Directed acylcic graph intermediate confounders mediator-outcome relation affected treatment\ndefine interventional direct effect :\n\\[\\begin{equation*}\n  \\psi_{\\text{PIDE}} = \\E(Y_{^\\prime,g_{M \\mid ^\\star,W}} -\n    Y_{\\star,g_{M \\mid ^\\star,W}}),\n\\end{equation*}\\]interventional indirect effect :\\[\\begin{equation*}\n  \\psi_{\\text{PIIE}} = \\E(Y_{^\\prime,g_{M \\mid ^\\prime,W}} -\n    Y_{^\\prime,g_{M \\mid ^\\star,W}}).\n\\end{equation*}\\]","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"simple-case-for-intuition-1","chapter":"6 Estimating natural and interventional effects","heading":"6.3 Simple case for intuition","text":"Consider simple data structure \\(O=(W, , Z, M, Y)\\). SCM represented \nDAG following causal models:\n\\[\\begin{align*}\nW & = f_W(U_W)\\\\\n& = f_A(W, U_A)\\\\\nZ & = f_Z(W, , U_Z)\\\\\nM & = f_M(W, , Z, U_M)\\\\\nY & = f_Y(W, , Z, M, U_Y),\n\\end{align*}\\]\n(\\(U_W, U_A, U_Z, U_M, U_Y\\)) exogenous random errors. assume \\(\\) \nsingle binary treatment, \\(Z\\) single binary intermediate confounder, \\(M\\)\nsingle binary mediator. restrictions distribution \n\\(W\\) \\(Y\\).\\(g_{M \\mid ^\\prime,W}\\) represents stochastic draw counterfactual,\nconditional distribution \\(M\\), described \nVanderWeele (2016):\\[\\begin{equation*}\n  g_{M \\mid ,W}(m, ^{\\star}, W) \\equiv g_{M \\mid ^{\\star}, W}(W) =\n    \\sum_{z=0}^1 \\P(M=1 \\mid Z=z,W) \\P(Z=z \\mid =^{\\star}, W).\n\\end{equation*}\\]follows, going assume \\(g_{M \\mid ,W}(m, ^{\\star}, W)\\)\nknown, estimated observed data, call\n\\(\\hat{g}_{M \\mid ^{\\star}, W}\\). going slightly alter usual\nidentification assumptions longer need assume exchangeability\n\\(\\) counterfactual \\(M\\) values. means remaining assumptions\ncontrolled direct effects.","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"estimation-using-g-computation","chapter":"6 Estimating natural and interventional effects","heading":"6.3.1 Estimation using G-Computation","text":"estimand \\(E(Y_{^\\prime, \\hat{g}_{M \\mid ^\\star,W}})\\) can identified\nvia sequential regression, provides framework \nG-computation-based estimator. procedure followsFit regression \\(Y\\) \\(M,Z,W\\). Predict outcome values \n\\(M=m\\). ’ll call result \\(\\bar{Q}_Y(M,Z,W)\\).Integrate \\(M\\) stochastic intervention\n\\(\\hat{g}_{M \\mid ^{\\star}, W}\\). can evaluating\n\\(\\E(Y \\mid M=m,Z=z,W)\\) \\(m\\) multiplying probability\n\\(M=m\\) \\(\\hat{g}_{M \\mid ^{\\star}, W}\\), summing \\(m\\).\n’ll call results \\(\\bar{Q}^{g}_M(Z,W)\\).Integrate \\(Z\\) set \\(=^\\prime\\). , can evaluating\npredicted values Step 2, setting \\(=^\\prime\\), \\(z\\),\nmultiplying prediction probability \\(Z=z\\) \\(=^\\prime\\).\n’ll call result \\(\\bar{Q}^{^\\prime}_Z(W)\\).Taking sample mean (marginalizing \\(W\\)) gives parameter\nestimate.","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"estimate-with-doubly-robust-methods-based-on-the-eif","chapter":"6 Estimating natural and interventional effects","heading":"6.3.2 Estimate with doubly robust methods based on the EIF","text":"EIF parameter \\(\\Psi(P)(^{\\prime}, \\hat{g}_{M \\mid ^{\\star},W})\\),\n, , \\(\\hat{g}_{M \\mid ^{\\star}, W}\\) assumed known, given :\n\\[\\begin{align*}\n  D^{\\star}(^{\\prime}, \\hat{g}_{M \\mid ^{\\star}, W}) &= \\sum_{k=0}^2\n      D_k^{\\star}(^{\\prime}, \\hat{g}_{M \\mid ^{\\star}, W}), \\text{ }\\\\\n  D^{\\star}_0(^{\\prime}, \\hat{g}_{M \\mid ^{\\star}, W}) &=\n      \\bar{Q}^{^{\\prime}}_{Z(W)} -\n      \\Psi(P)(^{\\prime}, \\hat{g}_{M \\mid ^{\\star}, W})\\\\\n  D^{\\star}_1(^{\\prime}, \\hat{g}_{M \\mid ^{\\star}, W}) &=\n      \\frac{(=^{\\prime})}{\\P(=^{\\prime} \\mid W)}(\\bar{Q}^{\\hat{g}}_M(Z,W)\n      - \\bar{Q}^{^{\\prime}}_{Z(W)})\\\\\n  D^{\\star}_2(^{\\prime}, \\hat{g}_{M \\mid ^{\\star}, W}) &=\n      \\frac{(=^{\\prime})\\{(M=1) \\hat{g}_{M \\mid ^{\\star}, W} +\n      (M=0)(1-\\hat{g}_{M \\mid ^{\\star}, W}) \\}}{\\P(=^{\\prime}}\n      &\\times (Y-\\bar{Q}_{Y(M,Z,W)}).\n\\end{align*}\\]","code":""},{"path":"estimating-natural-and-interventional-effects.html","id":"estimate-using-tmle","chapter":"6 Estimating natural and interventional effects","heading":"6.3.3 Estimate using TMLE","text":"estimate \\(g_{Z \\mid ^{\\star}, W}(W) = \\P(Z=1 \\mid =^{\\star}, W)\\) \nlogistic regression \\(Z\\) \\(, W\\) setting \\(=^{\\star}\\).estimate \\(g_{M \\mid z,W}(W) = \\P(M=1 \\mid Z=z, W)\\) logistic\nregression \\(M\\) \\(Z, W\\), setting \\(z=\\{0,1\\}\\).use quantities calculate \\(\\hat{g}_{M \\mid ^{\\star}, W} = \\hat{g}_{M \\mid z=1,W}\\hat{g}_{Z \\mid ^{\\star}, W} + \\hat{g}_{M \\mid z=0,W}(1-\\hat{g}_{Z|^{\\star}, W})\\).obtain estimate \\(\\bar{Q}_{Y}(M,Z,W)\\), predict values \\(Y\\) \nregression \\(Y\\) \\(M,Z,W\\), setting \\(m=1\\) \\(m=0\\), giving\n\\(\\hat{Y}(m=1, z, w)\\) \\(\\hat{Y}(m=0, z, w)\\).Estimate weights used initial targeting step:\n\\[\\begin{equation*}\n   h_1() = \\frac{(=)\\{(M=1)\\hat{g}_{M \\mid ^{\\star}, W} +\n     (M=0)(1-\\hat{g}_{M \\mid ^{\\star}, W}) \\}}{\\P(=)\\{(M=1)\n     g_{M \\mid Z,W} + (M=0)(1-g_{M \\mid Z,W}) \\}}\n\\end{equation*}\\]Estimate \\(\\hat{\\epsilon}\\) setting \\(\\epsilon\\) intercept \nweighted logistic regression model \\(Y\\) \n\\(\\text{logit}(\\hat{\\bar{Q}}_{Y}(M,Z,W))\\) offset weights\n\\(\\hat{h}_{1}()\\). (Note just one possible TMLE.)Estimate \\(\\hat{\\epsilon}\\) setting \\(\\epsilon\\) intercept \nweighted logistic regression model \\(Y\\) \n\\(\\text{logit}(\\hat{\\bar{Q}}_{Y}(M,Z,W))\\) offset weights\n\\(\\hat{h}_{1}()\\). (Note just one possible TMLE.)estimate \\(\\bar{Q}_{Y}(M,Z,W)\\) updated \n\\(\\hat{\\bar{Q}}^{\\star}_{Y}(M,Z,W) = \\hat{\\bar{Q}}_{Y}(\\epsilon_n)(M,Z,W)\\).estimate \\(\\bar{Q}_{Y}(M,Z,W)\\) updated \n\\(\\hat{\\bar{Q}}^{\\star}_{Y}(M,Z,W) = \\hat{\\bar{Q}}_{Y}(\\epsilon_n)(M,Z,W)\\).next integrate \\(M\\) \\(\\bar{Q}^{\\star}_{Y}(M,Z,W)\\). First, \nestimate \\(\\bar{Q}^{\\star}_{Y,n}(M,Z,W)\\) setting \\(m=1\\) \\(m=0\\), giving\n\\(\\bar{Q}^{\\star}_Y(m=1, z, w)\\) \\(\\bar{Q}^{\\star}_Y(m=0, z, w)\\). ,\nmultiply predicted values probabilities \n\\(\\hat{g}_{M \\mid ^{\\star},W}(W)\\) (\\(\\\\{, ^{\\star}\\}\\)), add\ntogether (.e., \\(\\bar{Q}^{\\hat{g}}_{M,n}(Z,W) = \\hat{Q}^{\\star}_Y(m=1, z, w) \\hat{g}_{M|^{\\star},W} + \\hat{Q}^{\\star}_Y(m=0, z, w)(1-\\hat{g}_{M|^{\\star},W})\\)).now fit regression \\(\\bar{Q}^{\\hat{g},\\star}_{M,n}(Z,W)\\) \\(W\\)\namong \\(=^\\prime\\). call predicted values \nregression \\(\\hat{\\bar{Q}}^{^\\prime}_{Z}(W)\\).(Note \\(\\) randomly assigned, need complete \nsecond targeting step.)empirical mean predicted values TML estimate \n\\(\\Psi(P)(^\\prime, \\hat{g}_{M \\mid ^{\\star}, W})\\).Repeat steps interventions. example, \nbinary \\(\\), execute steps total three times \nestimate:\n\\(\\Psi(P)(1,\\hat{g}_{M \\mid 1, W})\\),\n\\(\\Psi(P)(1,\\hat{g}_{M \\mid 0, W})\\), \n\\(\\Psi(P)(0,\\hat{g}_{M \\mid 0, W})\\).\n\\(\\Psi(P)(1,\\hat{g}_{M \\mid 1, W})\\),\\(\\Psi(P)(1,\\hat{g}_{M \\mid 0, W})\\), \\(\\Psi(P)(0,\\hat{g}_{M \\mid 0, W})\\).PIDE can obtained substituting estimates parameters\n\\(\\Psi(P)(,\\hat{g}_{M \\mid ^{\\star}, W}) - \\Psi(P)(^{\\star},\\hat{g}_{M \\mid ^{\\star}, W})\\) PIIE\ncan obtained substituting estimates parameters\n\\(\\Psi(P)(,\\hat{g}_{M \\mid ,W}) - \\Psi(P)(, \\hat{g}_{M \\mid ^{\\star}, W})\\).variance can estimated sample variance EIF (defined\n, substituting targeted fits) divided \\(n\\).","code":"\nzmodel <- \"z ~ a + w1 \"\nmmodel <- \"m ~ z + w1\"\nymodel <- \"y ~ m + z*w1\"\n\n# make gm and get counterfactual predictions\nzfit <- glm(formula = zmodel, family = \"binomial\", data = obsdat)\nmfit <- glm(formula = mmodel, family = \"binomial\", data = obsdat)\n\nza0 <- predict(zfit,\n  newdata = data.frame(w1 = obsdat$w1, a = 0),\n  type = \"response\"\n)\nza1 <- predict(zfit,\n  newdata = data.frame(w1 = obsdat$w1, a = 1),\n  type = \"response\"\n)\n\nmz1 <- predict(mfit,\n  newdata = data.frame(w1 = obsdat$w1, z = 1),\n  type = \"response\"\n)\nmz0 < -predict(mfit,\n  newdata = data.frame(w1 = obsdat$w1, z = 0),\n  type = \"response\"\n)\n\ngm0 <- (mz1 * za0) + (mz0 * (1 - za0))\ngma1 <- (mz1 * za1) + (mz0 * (1 - za1))\ntmpdat$qyinit <- cbind(\n  predict(glm(\n    formula = ymodel, family = \"binomial\",\n    data = data.frame(cbind(datw, z = z, m = m, y = y))\n  ),\n  newdata = data.frame(cbind(datw, z = z, m = m)), type = \"response\"\n  ),\n  predict(glm(\n    formula = ymodel, family = \"binomial\",\n    data = data.frame(cbind(datw, z = z, m = m, y = y))\n  ),\n  newdata = data.frame(cbind(datw, z = z, m = 0)), type = \"response\"\n  ),\n  predict(glm(\n    formula = ymodel, family = \"binomial\",\n    data = data.frame(cbind(datw, z = z, m = m, y = y))\n  ),\n  newdata = data.frame(cbind(datw, z = z, m = 1)), type = \"response\"\n  )\n)\npsa1 <- I(a == 1) / mean(a)\npsa0 <- I(a == 0) / mean(1 - a)\nmz <- predict(glm(\n  formula = mmodel, family = \"binomial\",\n  data = data.frame(cbind(datw, z = z, m = m))\n),\nnewdata = data.frame(cbind(datw, z = z)), type = \"response\"\n)\npsm <- (mz * m) + ((1 - mz) * (1 - m))\n\ntmpdat$ha1gma1 <- ((m * gma1 + (1 - m) * (1 - gma1)) / psm) * psa1 * svywt\ntmpdat$ha1gma0 <- ((m * gm + (1 - m) * (1 - gm)) / psm) * psa1 * svywt\ntmpdat$ha0gma0 <- ((m * gm + (1 - m) * (1 - gm)) / psm) * psa0 * svywt\n# for E(Y_{1,gmastar})\nepsilonma1g0 <- coef(glm(y ~ 1,\n  weights = tmpdat$ha1gma0,\n  offset = (qlogis(qyinit[, 1])),\n  family = \"quasibinomial\", data = tmpdat\n))\ntmpdat$qyupm0a1g0 <- plogis(qlogis(tmpdat$qyinit[, 2]) + epsilonma1g0)\ntmpdat$qyupm1a1g0 <- plogis(qlogis(tmpdat$qyinit[, 3]) + epsilonma1g0)\n\n# for E(Y_{1,gma})\nepsilonma1g1 <- coef(glm(y ~ 1,\n  weights = tmpdat$ha1gma1,\n  offset = (qlogis(qyinit[, 1])),\n  family = \"quasibinomial\", data = tmpdat\n))\ntmpdat$qyupm0a1g1 <- plogis(qlogis(tmpdat$qyinit[, 2]) + epsilonma1g1)\ntmpdat$qyupm1a1g1 <- plogis(qlogis(tmpdat$qyinit[, 3]) + epsilonma1g1)\n\n# for E(Y_{0,gmastar})\nepsilonma0g0 <- coef(glm(y ~ 1,\n  weights = tmpdat$ha0gma0,\n  offset = (qlogis(qyinit[, 1])),\n  family = \"quasibinomial\", data = tmpdat\n))\ntmpdat$qyupm0a0g0 <- plogis(qlogis(tmpdat$qyinit[, 2]) + epsilonma0g0)\ntmpdat$qyupm1a0g0 <- plogis(qlogis(tmpdat$qyinit[, 3]) + epsilonma0g0)\ntmpdat$Qma1g0 <- tmpdat$qyupm0a1g0 * (1 - gm) + tmpdat$qyupm1a1g0 * gm\ntmpdat$Qma1g1 <- tmpdat$qyupm0a1g1 * (1 - gma1) + tmpdat$qyupm1a1g1 * gma1\ntmpdat$Qma0g0 <- tmpdat$qyupm0a0g0 * (1 - gm) + tmpdat$qyupm1a0g0 * gm\nQzfita1g0 <- glm(\n  formula = paste(\"Qma1g0\", qmodel, sep = \"~\"),\n  data = tmpdat[tmpdat$a == 1, ], family = \"quasibinomial\"\n)\nQzfita1g1 <- glm(\n  formula = paste(\"Qma1g1\", qmodel, sep = \"~\"),\n  data = tmpdat[tmpdat$a == 1, ], family = \"quasibinomial\"\n)\nQzfita0g0 <- glm(\n  formula = paste(\"Qma0g0\", qmodel, sep = \"~\"),\n  data = tmpdat[tmpdat$a == 0, ], family = \"quasibinomial\"\n)\n\nQza1g0 <- predict(Qzfita1g0, type = \"response\", newdata = tmpdat)\nQza1g1 <- predict(Qzfita1g1, type = \"response\", newdata = tmpdat)\nQza0g0 <- predict(Qzfita0g0, type = \"response\", newdata = tmpdat)\ntmlea1m0 <- sum(Qzupa1g0 * svywt) / sum(svywt)\ntmlea1m1 <- sum(Qzupa1g1 * svywt) / sum(svywt)\ntmlea0m0 <- sum(Qzupa0g0 * svywt) / sum(svywt)\nnde <- tmlea1m0 - tmlea0m0\nnie <- tmlea1m1 - tmlea1m0\n# first get EIF\ntmpdat$qyupa1g0 <- plogis(qlogis(tmpdat$qyinit[, 1]) + epsilonma1g0)\ntmpdat$qyupa1g1 <- plogis(qlogis(tmpdat$qyinit[, 1]) + epsilonma1g1)\ntmpdat$qyupa0g0 <- plogis(qlogis(tmpdat$qyinit[, 1]) + epsilonma0g0)\n\neic1a1g0 <- tmpdat$ha1gma0 * (tmpdat$y - tmpdat$qyupa1g0)\neic2a1g0 <- psa1 * svywt * (tmpdat$Qma1g0 - Qzupa1g0)\neic3a1g0 <- Qzupa1g0 - tmlea1m0\neica1g0 <- eic1a1g0 + eic2a1g0 + eic3a1g0\n\neic1a1g1 <- tmpdat$ha1gma1 * (tmpdat$y - tmpdat$qyupa1g1)\neic2a1g1 <- psa1 * svywt * (tmpdat$Qma1g1 - Qzupa1g1)\neic3a1g1 <- Qzupa1g1 - tmlea1m1\neica1g1 <- eic1a1g1 + eic2a1g1 + eic3a1g1\n\neic1a0g0 <- tmpdat$ha0gma0 * (tmpdat$y - tmpdat$qyupa0g0)\neic2a0g0 <- psa0 * svywt * (tmpdat$Qma0g0 - Qzupa0g0)\neic3a0g0 <- Qzupa0g0 - tmlea0m0\neica0g0 <- eic1a0g0 + eic2a0g0 + eic3a0g0\n\n# estimands\nndeeic <- eica1g0 - eica0g0\nvareic <- var(ndeeic) / nrow(tmpdat)\n\nnieeic <- eica1g1 - eica1g0\nvarnieeic <- var(nieeic) / nrow(tmpdat)"},{"path":"estimating-natural-and-interventional-effects.html","id":"the-general-case","chapter":"6 Estimating natural and interventional effects","heading":"6.4 The general case","text":"Actually, want fixed parameter true, unknown\n\\(g_{M \\mid , W}\\) like \\(M\\) continuous/multi-dimensional.pain hand, Nima made easy--use package us\ncalled medoutcon! go \nnext.","code":""},{"path":"estimating-stochastic-effects.html","id":"estimating-stochastic-effects","chapter":"7 Estimating stochastic effects","heading":"7 Estimating stochastic effects","text":"[FILL ]","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"Kennedy, Edward H. 2018. “Nonparametric Causal Effects Based Incremental Propensity Score Interventions.” Journal American Statistical Association, nos. just-accepted.VanderWeele, Tyler J. 2016. “Mediation Analysis: Practitioner’s Guide.” Annual Review Public Health 37: 17–32.","code":""}]
