[{"path":"index.html","id":"welcome-to-ser","chapter":"Welcome to SER!","heading":"Welcome to SER!","text":"open source, reproducible vignette accompanies half-day workshop \nmodern methods causal mediation analysis, given SER 2021\nMeeting \nMonday, 24 May 2021. encourage use bookdown site, \nconvenience, also made workshop materials available \nPDF.\nDiscussion take place Slack – first join workspace\n,\n“#ser2021” channel.","code":""},{"path":"index.html","id":"about","chapter":"Welcome to SER!","heading":"0.1 About this workshop","text":"Causal mediation analysis can provide mechanistic understanding \nexposure impacts outcome, central goal epidemiology health sciences.\nHowever, rapid methodologic developments coupled formal courses\npresents challenges implementation. Beginning overview classical\ndirect indirect effects, workshop present recent advances \novercome limitations previous methods, allowing : () continuous\nexposures, (ii) multiple, non-independent mediators, (iii) effects\nidentifiable presence intermediate confounders affected exposure.\nEmphasis placed flexible, stochastic interventional direct \nindirect effects, highlighting may applied answer substantive\nepidemiological questions real-world studies. Multiply robust,\nnonparametric estimators causal effects, free open source R\npackages (medshift \nmedoutcon) application, \nintroduced.ensure translation real-world data analysis, workshop \nincorporate hands-R programming exercises allow participants practice \nimplementing statistical tools presented. recommended \nparticipants working knowledge basic notions causal inference,\nincluding counterfactuals identification (linking causal effect \nparameter estimable observed data distribution). Familiarity \nR programming language also recommended.","code":""},{"path":"index.html","id":"schedule","chapter":"Welcome to SER!","heading":"0.2 Workshop schedule","text":"10:00A-10:30A: introductions/mediation set 10:30A-11:15A: controlled direct effects, natural direct indirect effects,\ninterventional direct indirect effects 11:15A-11:45A: stochastic mediation estimands 11:45A-12:00P: choose estimand real-world examples 12:00P-12:15P break/discussion12:15P-12:45P: EIF 12:45P-01:00P: using EIF estimating natural direct\neffect 01:00P-01:45P: practice: R code estimation 01:45P-02:00P: Wrap-upNOTE: times listed Pacific Time.","code":""},{"path":"index.html","id":"instructors","chapter":"Welcome to SER!","heading":"0.3 About the instructors","text":"","code":""},{"path":"index.html","id":"iván-díaz","chapter":"Welcome to SER!","heading":"Iván Díaz","text":"Assistant Professor Weill Cornel Medicine. research focuses \ndevelopment non-parametric statistical methods causal inference \nobservational randomized studies complex datasets, using machine\nlearning. includes limited mediation analysis, methods \ncontinuous exposures, longitudinal data including survival analysis, \nefficiency guarantees covariate adjustment randomized trials. also\ninterested general semi-parametric theory, machine learning, \nhigh-dimensional data.","code":""},{"path":"index.html","id":"nima-hejazi","chapter":"Welcome to SER!","heading":"Nima Hejazi","text":"PhD candidate biostatistics UC Berkeley, working joint\ndirection Mark van der Laan Alan Hubbard. research interests fall \nintersection causal inference machine learning, drawing ideas \nnon/semi-parametric estimation large, flexible statistical models. Particular\nareas current emphasis include causal mediation analysis, corrections \noutcome-dependent sampling designs, targeted loss-based estimation, \napplications vaccine efficacy trials. also passionate statistical\ncomputing open source software development applied statistics.","code":""},{"path":"index.html","id":"kara-rudolph","chapter":"Welcome to SER!","heading":"Kara Rudolph","text":"Assistant Professor Epidemiology Columbia University. research\ninterests developing applying causal inference methods understand\nsocial contextual influences mental health, substance use, violence\ndisadvantaged, urban areas United States. current work focuses \ndeveloping methods transportability mediation, subsequently applying\nmethods understand aspects school peer environments\nmediate relationships neighborhood factors adolescent drug use\nacross populations. generally, work generalizing/ transporting\nfindings study samples target populations identifying subpopulations\nlikely benefit interventions contributes efforts optimally\ntarget available policy program resources.","code":""},{"path":"index.html","id":"repro","chapter":"Welcome to SER!","heading":"0.4 Reproduciblity","text":"workshop materials written using bookdown,\ncomplete source available \nGitHub. version book\nbuilt R version 4.0.5 (2021-03-31), pandoc version r rmarkdown::pandoc_version(), following packages:","code":""},{"path":"index.html","id":"setup","chapter":"Welcome to SER!","heading":"0.5 Setup instructions","text":"","code":""},{"path":"index.html","id":"r-and-rstudio","chapter":"Welcome to SER!","heading":"0.5.1 R and RStudio","text":"R RStudio separate downloads installations. R \nunderlying statistical computing environment. RStudio graphical integrated\ndevelopment environment (IDE) makes using R much easier \ninteractive. need install R install RStudio.","code":""},{"path":"index.html","id":"windows","chapter":"Welcome to SER!","heading":"0.5.1.1 Windows","text":"","code":""},{"path":"index.html","id":"if-you-already-have-r-and-rstudio-installed","chapter":"Welcome to SER!","heading":"0.5.1.1.1 If you already have R and RStudio installed","text":"Open RStudio, click “Help” > “Check updates”. new version \navailable, quit RStudio, download latest version RStudio.check version R using, start RStudio first thing\nappears console indicates version R \nrunning. Alternatively, can type sessionInfo(), also display\nversion R running. Go CRAN\nwebsite check whether \nrecent version available. , please download install . \ncan check \ninformation remove old versions system \nwish .","code":""},{"path":"index.html","id":"if-you-dont-have-r-and-rstudio-installed","chapter":"Welcome to SER!","heading":"0.5.1.1.2 If you don’t have R and RStudio installed","text":"Download R \nCRAN website.Run .exe file just downloadedGo RStudio download\npageUnder Installers select RStudio x.yy.zzz - Windows\nXP/Vista/7/8 (x, y, z represent version numbers)Double click file install itOnce ’s installed, open RStudio make sure works don’t get \nerror messages.","code":""},{"path":"index.html","id":"macos-mac-os-x","chapter":"Welcome to SER!","heading":"0.5.1.2 macOS / Mac OS X","text":"","code":""},{"path":"index.html","id":"if-you-already-have-r-and-rstudio-installed-1","chapter":"Welcome to SER!","heading":"0.5.1.2.1 If you already have R and RStudio installed","text":"Open RStudio, click “Help” > “Check updates”. new version \navailable, quit RStudio, download latest version RStudio.check version R using, start RStudio first thing\nappears terminal indicates version R running.\nAlternatively, can type sessionInfo(), also display \nversion R running. Go CRAN\nwebsite check whether \nrecent version available. , please download install .","code":""},{"path":"index.html","id":"if-you-dont-have-r-and-rstudio-installed-1","chapter":"Welcome to SER!","heading":"0.5.1.2.2 If you don’t have R and RStudio installed","text":"Download R \nCRAN website.Select .pkg file latest R versionDouble click downloaded file install RIt also good idea install XQuartz (needed\npackages)Go RStudio download\npageUnder Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit)\n(x, y, z represent version numbers)Double click file install RStudioOnce ’s installed, open RStudio make sure works don’t get \nerror messages.","code":""},{"path":"index.html","id":"linux","chapter":"Welcome to SER!","heading":"0.5.1.3 Linux","text":"Follow instructions distribution\nCRAN, provide information\nget recent version R common distributions. \ndistributions, use package manager (e.g., Debian/Ubuntu run\nsudo apt-get install r-base, Fedora sudo yum install R), \ndon’t recommend approach versions provided \nusually date. case, make sure least R 3.3.1.Go RStudio download\npageUnder Installers select version matches distribution, \ninstall preferred method (e.g., Debian/Ubuntu sudo dpkg -rstudio-x.yy.zzz-amd64.deb terminal).’s installed, open RStudio make sure works don’t get \nerror messages.setup instructions adapted written Data Carpentry: R\nData Analysis Visualization Ecological\nData.","code":""},{"path":"mediation.html","id":"mediation","chapter":"1 Preliminaries on causal mediation analysis","heading":"1 Preliminaries on causal mediation analysis","text":"","code":""},{"path":"mediation.html","id":"motivating-study","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.1 Motivating study","text":"differences effects treatment (comparing two medications opioid use disorder, naltrexone vs buprenorphine) risk relapse operate mediators adherence, opioid use, pain, depressive symptoms? (Rudolph et al. 2020)\n","code":""},{"path":"mediation.html","id":"what-is-causal-mediation-analysis","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.2 What is causal mediation analysis?","text":"Causal mediation analyses assess paths behave interventionsStatistical mediation analyses assess associations variables\n","code":""},{"path":"mediation.html","id":"why-are-the-methods-that-we-will-discuss-today-important","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.2.1 Why are the methods that we will discuss today important?","text":"Assume interested effect treatment assignment \\(\\) (naltrexone vs.\nbuprenorphine) outcome \\(Y\\) (risk relapse) mediators \\(M\\)\n(opioid use, pain, depressive symptoms)pre-treatment confounders \\(W\\)confounder \\(Z\\) \\(M\\rightarrow Y\\) ffected treatment assignment (adherence)fit following models:\n\\[\\begin{align}\n    \\E(M\\mid =, W=w, Z=z) & = \\gamma_0 + \\gamma_1 + \\gamma_2 w + \\gamma_3 z \\\\\n    \\E(Y\\mid M=m, =, W=w, Z=z) & = \\beta_0 + \\beta_1 m + \\beta_2 + \\beta_3 w + \\beta_4 z\n  \\end{align}\\]product \\((\\gamma_1\\beta_1)\\) proposed measure effect\n\\(\\) \\(Y\\) \\(M\\)Causal interpretation problems method:\nsee parameter interpreted causal effect\nsee parameter interpreted causal effect","code":""},{"path":"mediation.html","id":"r-example","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.2.2 R Example:","text":"Assume pre-treamtment confounder \\(Y\\) \\(M\\), denote \\(W\\)simplicity, assume \\(\\) randomizedWe’ll generate really large sample data generating mechanism \nconcerned sampling errorsNote indirect effect (.e., effect \\(M\\)) example\nnonzero (pathway \\(\\rightarrow Z \\rightarrow M \\rightarrow Y\\))Let’s see product coefficients method say:Among things, workshop:provide understanding method fails exampleWe study estimators robust misspecification models","code":"\nn <- 1e7\nw <- rnorm(n)\na <- rbinom(n, 1, 0.5)\nz <- rbinom(n, 1, 0.2 * a + 0.3)\nm <- rnorm(n, w + z)\ny <- rnorm(n, m + w - a + z)\nlm_y <- lm(y ~ m + a + w + z)\nlm_m <- lm(m ~ a + w + z)\n## product of coefficients\ncoef(lm_y)[2] * coef(lm_m)[2]"},{"path":"mediation.html","id":"causal-mediation-models","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.3 Causal mediation models","text":"workshop use directed acyclic graphs. focus two\ntypes graph:","code":""},{"path":"mediation.html","id":"no-intermediate-confounders","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.3.1 No intermediate confounders","text":"","code":""},{"path":"mediation.html","id":"intermediate-confounders","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.3.2 Intermediate confounders","text":"graphs can interpreted non-parametric structural equation model\n(NPSEM), also known structural causal model (SCM):\\[\\begin{align}\n  W & = f_W(U_W)\\\\\n  & = f_A(W, U_A)\\\\\n  Z & = f_Z(W, , U_Z)\\\\\n  M & = f_M(W, , Z, U_M)\\\\\n  Y & = f_Y(W, , Z, M, U_Y)\n\\end{align}\\]\\(U=(U_W, U_A, U_Z, U_M, U_Y)\\) vector unmeasured exogenous\nfactors affecting systemThe functions \\(f\\) assumed fixed unknownWe posit model system equations nature uses geenrate \ndataTherefore leave functions \\(f\\) unspecified (.e., know \ntrue nature mechanisms)Sometimes know something: e.g., \\(\\) randomized know \\(=f_A(U_A)\\)\n\\(U_A\\) flip coin (.e., independent everything).","code":""},{"path":"mediation.html","id":"counterfactuals","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.4 Counterfactuals","text":"define effects interest using counterfactualsCounterfactuals hypothetical random variables \nobserved alternative world something happened, possibly\ncontrary fact \\(Y_a\\) counterfactual variable hypothetical world \\(\\P(=)=1\\)\nprobability one\\(Y_{,m}\\) counterfactual outcome world \\(\\P(=,M=m)=1\\)\\(M_a\\) counterfactual variable representing mediator world\n\\(\\P(=)=1\\).","code":""},{"path":"mediation.html","id":"how-are-counterfactuals-defined","chapter":"1 Preliminaries on causal mediation analysis","heading":"1.4.1 How are counterfactuals defined?","text":"NPSEM framework, counterfactuals quantities derived \nmodel.Take example DAG Figure 1.2:\n\\[\\begin{align}\n  Y_a  &= f_Y(W, , Z_a, M_a, U_Y)\\\\\n  Y_{,m}  &= f_Y(W, , Z_a, m, U_Y)\\\\\n  M_a  &= f_M(W, , Z_a, U_M)\n\\end{align}\\]can also define nested counterfactualsFor example, \\(\\) binary, can think following counterfactual\n\\[\\begin{equation*}\n  Y_{1, M_0} = f_Y(W, 1, Z_1, M_0, U_Y)\n\\end{equation*}\\]Interpreted outcome individual hypothetical world \ntreatment given mediator held value \ntaken treatmentCausal effects defined terms distribution \ncounterfactuals., causal effects give information happened\nhypothetical world.","code":""},{"path":"estimands.html","id":"estimands","chapter":"2 Path-specific casual mediation effect types","heading":"2 Path-specific casual mediation effect types","text":"Controlled direct effectsNatural direct indirect effectsInterventional direct indirect effects","code":""},{"path":"estimands.html","id":"controlled-direct-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.1 Controlled direct effects","text":"Set mediator reference value \\(M=m\\) uniformly everyone \npopulationCompare \\(=1\\) vs \\(=0\\) \\(M=m\\) fixed\\[\\psi_{\\text{CDE}} = \\E(Y_{1,m} - Y_{0,m}) \\]","code":""},{"path":"estimands.html","id":"identification-assumptions","chapter":"2 Path-specific casual mediation effect types","heading":"2.1.1 Identification assumptions:","text":"Confounder assumptions:\n\\(\\indep Y_{,m} \\mid W\\)\n\\(M \\indep Y_{,m} \\mid W, \\)\n\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, \\)Positivity assumptions:\n\\(\\P(M = m \\mid =, W) > 0 \\text{  } .e.\\)\n\\(\\P(=\\mid W) > 0 \\text{  } .e.\\)\n\\(\\P(M = m \\mid =, W) > 0 \\text{  } .e.\\)\\(\\P(=\\mid W) > 0 \\text{  } .e.\\)identification assumptions, controlled direct effect can \nidentified:\n\\[ \\E(Y_{1,m} - Y_{0,m}) = \\E\\{\\color{ForestGreen}{\\E(Y \\mid =1, M=m, W) - \\E(Y \\mid =0, M=m, W)}\\}\\]intuition formula R, let’s continue toy example:First fit correct model outcomeAssume like CDE \\(m=0\\)generate predictions \\[\\color{ForestGreen}{\\E(Y \\mid =1, M=m, W)}\n\\text{ }\\color{ForestGreen}{\\E(Y \\mid =0, M=m, W)}:\\]compute difference predicted values\n\\(\\color{ForestGreen}{\\E(Y \\mid =1, M=m, W) - \\E(Y \\mid =0, M=m, W)}\\), \naverage across values \\(W\\)","code":"\nn <- 1e6\nw <- rnorm(n)\na <- rbinom(n, 1, 0.5)\nm <- rnorm(n, w + a)\ny <- rnorm(n, w + a + m)\nlm_y <- lm(y ~ m + a + w)\npred_y1 <- predict(lm_y, newdata = data.frame(a = 1, m = 0, w = w))\npred_y0 <- predict(lm_y, newdata = data.frame(a = 0, m = 0, w = w))\n## CDE at m = 0\nmean(pred_y1 - pred_y0)"},{"path":"estimands.html","id":"is-this-the-estimand-i-want","chapter":"2 Path-specific casual mediation effect types","heading":"2.1.2 Is this the estimand I want?","text":"Makes sense can intervene directly \\(M\\)\ncan think policy set everyone single constant\nlevel \\(m \\\\mathcal{M}\\).\nJ. Pearl calls prescriptive.\nCan think example?\nAir pollution, rescue inhaler dosage, hospital visits\nprovide decomposition average treatment effect \ndirect indirect effects\ncan think policy set everyone single constant\nlevel \\(m \\\\mathcal{M}\\).J. Pearl calls prescriptive.Can think example?Air pollution, rescue inhaler dosage, hospital visitsDoes provide decomposition average treatment effect \ndirect indirect effectsWhat research question doesn’t involve intervening directly \nmediator?want decompose average treatment effect direct \nindirect counterparts?","code":""},{"path":"estimands.html","id":"natural-direct-and-indirect-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.2 Natural direct and indirect effects","text":"Still using DAG ,Recall definition nested counterfactual\\[\\begin{equation*}\n    Y_{1, M_0} = f_Y(W, 1, Z_1, M_0, U_Y)\n\\end{equation*}\\]Interpreted outcome individual hypothetical world \ntreatment given mediator held value \ntaken treatmentInterpreted outcome individual hypothetical world \ntreatment given mediator held value \ntaken treatmentRecall , definition counterfactuals\n\\[\\begin{equation*}\nY_{1, M_1} = Y_1\n\\end{equation*}\\]Recall , definition counterfactuals\n\\[\\begin{equation*}\nY_{1, M_1} = Y_1\n\\end{equation*}\\]can decompose average treatment effect \\(E(Y_1-Y_0)\\) follows\\[\\begin{equation*}\n\\E[Y_{1,M_1} - Y_{0,M_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{M_1}} -\n    Y_{\\color{red}{1},\\color{blue}{M_0}}]}_{\\text{natural indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{M_0}} -\n    Y_{\\color{blue}{0},\\color{red}{M_0}}]}_{\\text{natural direct effect}}\n\\end{equation*}\\]Natural direct effect (NDE): Varying treatment keeping mediator\nfixed value taken treatmentNatural indirect effect (NIE): Varying mediator value \ntaken treatment value taken control,\nkeeping treatment fixed","code":""},{"path":"estimands.html","id":"identification-assumptions-1","chapter":"2 Path-specific casual mediation effect types","heading":"2.2.1 Identification assumptions:","text":"\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, \\)\\(\\indep M_a \\mid W\\)\\(M_0 \\indep Y_{1,m} \\mid W\\)positivity assumptions","code":""},{"path":"estimands.html","id":"cross-world-independence-assumption","chapter":"2 Path-specific casual mediation effect types","heading":"2.2.2 Cross-world independence assumption","text":"\\(M_0 \\indep Y_{1,m} \\mid W\\) mean?Conditional \\(W\\), knowledge mediator value absence \ntreatment, \\(M_0\\),\nprovides information outcome treatment, \\(Y_{1,m}\\).Can think data-generating mechanism violate \nassumption?Example: randomized study, whenever believe treatment assignment\nworks adherence (.e., almost\nalways), violating assumption (later).Cross-world assumptions problematic reasons, including:\ncan never design randomized study assumption holds \ndesign.\ncan never design randomized study assumption holds \ndesign.cross-world assumption holds, can write NDE weighted average\ncontrolled direct effects level \\(M=m\\).\\[\\E \\sum_m \\{\\E(Y_{1,m} \\mid W) - \\E(Y_{0,m} \\mid W)\\} \\P(M_{0}=m\n\\mid W)\\]CDE(\\(m\\)) constant across \\(m\\), CDE = NDE.","code":""},{"path":"estimands.html","id":"identification-formula","chapter":"2 Path-specific casual mediation effect types","heading":"2.2.3 Identification formula:","text":"identification assumptions, natural direct effect can \nidentified:\n\\[\\begin{equation*}\n\\E(Y_{1,M_0} - Y_{0,M_0}) =\n\\E[\\color{Goldenrod}{\\E\\{}\\color{ForestGreen}{\\E(Y \\mid =1, M, W) -\n\\E(Y \\mid =0, M, W)}\\color{Goldenrod}{\\mid =0,W\\}}]\n\\end{equation*}\\]identification assumptions, natural direct effect can \nidentified:\n\\[\\begin{equation*}\n\\E(Y_{1,M_0} - Y_{0,M_0}) =\n\\E[\\color{Goldenrod}{\\E\\{}\\color{ForestGreen}{\\E(Y \\mid =1, M, W) -\n\\E(Y \\mid =0, M, W)}\\color{Goldenrod}{\\mid =0,W\\}}]\n\\end{equation*}\\]natural indirect effect can identified similarly.natural indirect effect can identified similarly.Let’s dissect formula R:Let’s dissect formula R:First fit correct model outcomeThen generate predictions \\[\\color{ForestGreen}{\\E(Y \\mid =1, M, W)}\n\\text{ }\\color{ForestGreen}{\\E(Y \\mid =0, M, W)}\\] \\(\\) fixed \nletting \\(M\\) \\(W\\) take observed\nvaluesThen compute difference predicted values\n\\[\\color{ForestGreen}{\\E(Y \\mid =1, M, W) - \\E(Y \\mid =0, M, W)},\\]use difference pseudo-outcome regression \\(\\) \\(W\\):\n\\[\\color{Goldenrod}{\\E\\{}\\color{ForestGreen}{\\E(Y \\mid =1, M, W) - \\E(Y \\mid\n=0, M, W)}\\color{Goldenrod}{\\mid =0,W\\}}\\]Now predict value pseudo-outcome \\(=0\\), average \nresult","code":"\nn <- 1e6\nw <- rnorm(n)\na <- rbinom(n, 1, 0.5)\nm <- rnorm(n, w + a)\ny <- rnorm(n, w + a + m)\nlm_y <- lm(y ~ m + a + w)\npred_y1 <- predict(lm_y, newdata = data.frame(a = 1, m = m, w = w))\npred_y0 <- predict(lm_y, newdata = data.frame(a = 0, m = m, w = w))\npseudo <- pred_y1 - pred_y0\nlm_pseudo <- lm(pseudo ~ a + w)\npred_pseudo <- predict(lm_pseudo, newdata = data.frame(a = 0, w = w))\n## NDE:\nmean(pred_pseudo)"},{"path":"estimands.html","id":"is-this-the-estimand-i-want-1","chapter":"2 Path-specific casual mediation effect types","heading":"2.2.4 Is this the estimand I want?","text":"Makes sense intervene \\(\\) directly \\(M\\).Want understand natural mechanism underlying association/ total\neffect. J. Pearl calls descriptive.NDE + NIE = total effect (ATE).Okay assumptions.data structure involves post-treatment confounder \nmediator-outcome relationship (e.g., adherence)?","code":""},{"path":"estimands.html","id":"unidentifiability-of-the-nde-and-nie-in-this-setting","chapter":"2 Path-specific casual mediation effect types","heading":"2.2.5 Unidentifiability of the NDE and NIE in this setting","text":"example, natural direct indirect effects unidentifiable observed data \\(O=(W,,Z,M,Y)\\).reason cross-world counterfactual\nassumption\n\\[\\begin{equation*}\nY_{1,m}\\indep M_0\\mid W\n\\end{equation*}\\]\nhold directed acyclic graph.Technically, reason intervention setting \\(=1\\)\n(necessary definition \\(Y_{1,m}\\)) induces counterfactual variable\n\\(Z_1\\).Likewise, intervention setting \\(=0\\) (necessary definition \n\\(M_0\\)) induces counterfactual \\(Z_0\\).variables \\(Z_1\\) \\(Z_0\\) correlated share unmeasured\ncommon causes, \\(U_Z\\).variable \\(Z_1\\) correlated \\(Y_{1,m}\\), variable \\(Z_0\\) \ncorrelated \\(M_0\\), counterfactual outcomes \nhypothetical worlds.see definition counterfactual causal structural\nmodel:\n\\[\\begin{align*}\nY_{1,m} &= f_Y(W, 1, Z_1, m, U_Y), \\text{ }\\\\\nM_0 &= f_M(W, 0, Z_0, U_M)\\\\\n\\end{align*}\\]\ncorrelated even adjusting \\(W\\) virtue \\(Z_1\\) \\(Z_0\\) \ncorrelated.Intuitively:\\(Z\\) confounder relation \\(M \\rightarrow Y\\), requires\nadjustmentBut \\(Z\\) pathway \\(\\rightarrow Y\\), precludes adjustmentNote: CDEs still identified setting. can identified \nestimated similarly longitudinal data sructure two-time-point\nintervention.","code":""},{"path":"estimands.html","id":"interventional-indirect-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.3 Interventional (in)direct effects","text":"Let \\(G_a\\) denote random draw distribution \\(M_a \\mid W\\)Define counterfactual \\(Y_{1,G_0}\\) counterfactual\nvariable hypothetical world \\(\\) set \\(=1\\) \\(M\\) \nset \\(M=G_0\\) probability one.Define \\(Y_{0,G_0}\\) \\(Y_{1,G_1}\\) similarlyThen can define:\n\\[\\begin{equation*}\n\\E[Y_{1,G_1} - Y_{0,G_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{G_1}} -\n  Y_{\\color{red}{1},\\color{blue}{G_0}}]}_{\\text{interventional indirect effect}} +\n  \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{G_0}} -\n  Y_{\\color{blue}{0},\\color{red}{G_0}}]}_{\\text{interventional direct effect}}\n\\end{equation*}\\]Note \\(\\E[Y_{1,G_1} - Y_{0,G_0}]\\) still total effect treatment,\neven different ATE \\(\\E[Y_{1} - Y_{0}]\\)gain ability solve problem, lose terms interpretation\ncausal effect (decompose ATE)","code":""},{"path":"estimands.html","id":"an-alternative-definition-of-the-effects","chapter":"2 Path-specific casual mediation effect types","heading":"2.3.1 An alternative definition of the effects:","text":"defined \\(G_a\\) random draw distribution \\(M_a \\mid W\\)instead define \\(G_a\\) random draw distribution \\(M_a \\mid (Z_a,W)\\)turns indirect effect defined way measures path\n\\(\\rightarrow M \\rightarrow Y\\), path \\(\\rightarrow Z\\rightarrow M \\rightarrow Y\\)may important reasons choose one another (e.g., survival\nanalyses want distribution conditional \\(Z\\), instrumental\nvariable designs doesn’t make sense condition \\(Z\\))","code":""},{"path":"estimands.html","id":"identification-assumptions-2","chapter":"2 Path-specific casual mediation effect types","heading":"2.3.2 Identification assumptions:","text":"\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, , Z\\)\\(\\indep M_a \\mid W\\)positivity assumptions.assumptions, population interventional direct indirect effect identified:\n\\[\\begin{align*}\n  \\E&(Y_{, G_{'}}) = \\\\\n    &\\E\\left[\\color{Purple}{\\E\\left\\{\\color{Goldenrod}{\\sum_z}\n    \\color{ForestGreen}{\\E(Y \\mid =, Z=z, M, W)}\n    \\color{Goldenrod}{\\P(Z=z \\mid =, W)}\\mid =', W\\right\\}}\\right]\n\\end{align*}\\]Let’s dissect formula R:Let us compute \\(\\E(Y_{1, G_0})\\) (\\(= 1\\), \\('=0\\)).First, fit regression model outcome, compute\n\\[\\color{ForestGreen}{\\E(Y \\mid =, Z=z, M, W)}\\] values \\(z\\)Now fit true model \\(Z \\mid , W\\) get conditional\nprobability \\(Z=1\\) fixing \\(=1\\)Now compute following pseudo-outcome:\n\\[\\color{Goldenrod}{\\sum_z}\\color{ForestGreen}{\\E(Y \\mid =, Z=z, M, W)}\n\\color{Goldenrod}{\\P(Z=z \\mid =, w)}\\]Now regress pseudo-outcome \\(,W\\), compute predictions\nsetting \\(=0\\), , \\[\\color{Purple}{\\E\\left\\{\\color{Goldenrod}{\\sum_z}\n\\color{ForestGreen}{\\E(Y \\mid =, Z=z, M, W)}\n\\color{Goldenrod}{\\P(Z=z \\mid =, w)}\\mid =', W\\right\\}}\\]finally, just average predictions!\\((,')=(1,0)\\). Can \\((,')=(1,1)\\), \n\\((,')=(0,0)\\) obtain effect decomposition\\[\\begin{equation*}\n  \\E[Y_{1,G_1} - Y_{0,G_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\n    \\color{blue}{G_1}} -\n    Y_{\\color{red}{1},\n    \\color{blue}{G_0}}]}_{\\text{interventional indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{G_0}} -\n    Y_{\\color{blue}{0},\n    \\color{red}{G_0}}]}_{\\text{interventional direct effect}}\n\\end{equation*}\\]","code":"\nn <- 1e6\nw <- rnorm(n)\na <- rbinom(n, 1, 0.5)\nz <- rbinom(n, 1, 0.5 + 0.2 * a)\nm <- rnorm(n, w + a - z)\ny <- rnorm(n, w + a + z + m)\nlm_y <- lm(y ~ m + a + z + w)\npred_a1z0 <- predict(lm_y, newdata = data.frame(m = m, a = 1, z = 0, w = w))\npred_a1z1 <- predict(lm_y, newdata = data.frame(m = m, a = 1, z = 1, w = w))\nprob_z <- lm(z ~ a)\npred_z <- predict(prob_z, newdata = data.frame(a = 1))\npseudo_out <- pred_a1z0 * (1 - pred_z) + pred_a1z1 * pred_z\nfit_pseudo <- lm(pseudo_out ~ a + w)\npred_pseudo <- predict(fit_pseudo, data.frame(a = 0, w = w))\n## Mean(Y(1, G(0)))\nmean(pred_pseudo)"},{"path":"estimands.html","id":"is-this-the-estimand-i-want-2","chapter":"2 Path-specific casual mediation effect types","heading":"2.3.3 Is this the estimand I want?","text":"Makes sense intervene \\(\\) directly \\(M\\).Goal understand natural mechanism underlying association total\neffect.Okay assumptions!","code":""},{"path":"estimands.html","id":"estimand-summary","chapter":"2 Path-specific casual mediation effect types","heading":"2.4 Estimand Summary","text":"","code":""},{"path":"stochastic.html","id":"stochastic","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3 Stochastic Direct and Indirect Effects","text":"","code":""},{"path":"stochastic.html","id":"definition-of-the-effects","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3.1 Definition of the effects","text":"Consider following directed acyclic graph.","code":""},{"path":"stochastic.html","id":"motivation-for-stochastic-interventions","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3.2 Motivation for stochastic interventions","text":"far discussed controlled, natural, interventional ()direct effectsThese effects require \\(0 < \\P(=1\\mid W) < 1\\)defined binary exposuresWhat can positivity assumption hold exposure\ncontinuous?Solution: can use stochastic effects","code":""},{"path":"stochastic.html","id":"definition-of-stochastic-effects","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3.3 Definition of stochastic effects","text":"two possible ways defining stochastic effects:Consider effect intervention exposure drawn \ndistribution\nexample incremental propensity score interventions\nexample incremental propensity score interventionsConsider effect intervention post-intervention exposure \nfunction actually received exposure\nexample modified treatment policies\nexample modified treatment policiesIn cases \\(\\mid W\\) non-deterministic intervention, thus name\nstochastic intervention","code":""},{"path":"stochastic.html","id":"example-incremental-propensity-score-interventions-ipsi-kennedy2018nonparametric","chapter":"3 Stochastic Direct and Indirect Effects","heading":"Example: incremental propensity score interventions (IPSI) (Kennedy 2018)","text":"","code":""},{"path":"stochastic.html","id":"definition-of-the-intervention","chapter":"3 Stochastic Direct and Indirect Effects","heading":"Definition of the intervention","text":"Assume \\(\\) binary, \\(\\P(=1\\mid W=w) = g(1\\mid w)\\) propensity scoreConsider intervention individual receives intervention\nprobability \\(g_\\delta(1\\mid w)\\), equal \n\\[\\begin{equation*}\n  g_\\delta(1\\mid w)=\\frac{\\delta g(1\\mid w)}{\\delta g(1\\mid w) +\n  1 - g(1\\mid w)}\n\\end{equation*}\\]e.g., draw post-intervention exposure Bernoulli variable \nprobability \\(g_\\delta(1\\mid w)\\)value \\(\\delta\\) user givenLet \\(A_\\delta\\) denote post-intervention exposure distributionSome algebra shows \\(\\delta\\) odds ratio comparing pre- \npost-intervention exposure distributions\n\\[\\begin{equation*}\n  \\delta = \\frac{\\text{odds}(A_\\delta = 1\\mid W=w)}\n  {\\text{odds}(= 1\\mid W=w)}\n\\end{equation*}\\]Interpretation: happen \nworld odds receiving treatment increased \\(\\delta\\)Let \\(Y_{A_\\delta}\\) denote outcome hypothetical world","code":""},{"path":"stochastic.html","id":"illustrative-application-for-ipsis","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3.3.0.1 Illustrative application for IPSIs","text":"Consider effect participation sports children’s BMIMediation snacking, exercising, etc.Intervention: individual, increase odds participating \nsports \\(\\delta=2\\)post-intervention exposure draw \\(A_\\delta\\) Bernoulli\ndistribution probability \\(g_\\delta(1\\mid w)\\)","code":""},{"path":"stochastic.html","id":"example-modified-treatment-policies-mtp-diaz2020causal","chapter":"3 Stochastic Direct and Indirect Effects","heading":"Example: modified treatment policies (MTP) (Dı́az and Hejazi 2020)","text":"","code":""},{"path":"stochastic.html","id":"definition-of-the-intervention-1","chapter":"3 Stochastic Direct and Indirect Effects","heading":"Definition of the intervention","text":"Consider continuous exposure \\(\\) taking values real numbersConsider intervention assigns exposure \\(A_\\delta = - \\delta\\)Example: \\(\\) pollution measured \\(PM_{2.5}\\) interested \nintervention reduces \\(PM_{2.5}\\) concentration amount \\(\\delta\\)","code":""},{"path":"stochastic.html","id":"mediation-analysis-for-stochastic-interventions","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3.3.1 Mediation analysis for stochastic interventions","text":"total effect IPSI can computed contrast outcome \nintervention vs intervention:\n\\[\\begin{equation*}\n  \\psi = \\E[Y_{A_\\delta} - Y]\n\\end{equation*}\\]total effect IPSI can computed contrast outcome \nintervention vs intervention:\n\\[\\begin{equation*}\n  \\psi = \\E[Y_{A_\\delta} - Y]\n\\end{equation*}\\]Recall NPSEM\n\\[\\begin{align}\n  W & = f_W(U_W)\\\\\n  & = f_A(W, U_A)\\\\\n  M & = f_M(W, , U_M)\\\\\n  Y & = f_Y(W, , M, U_Y)\n\\end{align}\\]Recall NPSEM\n\\[\\begin{align}\n  W & = f_W(U_W)\\\\\n  & = f_A(W, U_A)\\\\\n  M & = f_M(W, , U_M)\\\\\n  Y & = f_Y(W, , M, U_Y)\n\\end{align}\\]\n\\[\\begin{align*}\nM_{A_\\delta} & = f_M(W, A_\\delta, U_M)\\\\\nY_{A_\\delta} & = f_Y(W, A_\\delta, M_{A_\\delta}, U_Y)\n\\end{align*}\\]\n\\[\\begin{align*}\nM_{A_\\delta} & = f_M(W, A_\\delta, U_M)\\\\\nY_{A_\\delta} & = f_Y(W, A_\\delta, M_{A_\\delta}, U_Y)\n\\end{align*}\\]Thus, \\(Y_{A_\\delta} = Y_{A_\\delta, M_{A_\\delta}}\\) \\(Y = Y_{,M_{}}\\)Thus, \\(Y_{A_\\delta} = Y_{A_\\delta, M_{A_\\delta}}\\) \\(Y = Y_{,M_{}}\\)Let us introduce counterfactual \\(Y_{A_\\delta, M}\\), interpreted \noutcome observed world intervention \\(\\) performed \nmediator fixed value taken intervention:\n\\[Y_{A_\\delta, M}  = f_Y(W, A_\\delta, M_{A_\\delta}, U_Y)\\]Let us introduce counterfactual \\(Y_{A_\\delta, M}\\), interpreted \noutcome observed world intervention \\(\\) performed \nmediator fixed value taken intervention:\n\\[Y_{A_\\delta, M}  = f_Y(W, A_\\delta, M_{A_\\delta}, U_Y)\\]can decompose total effect :\n\\[\\begin{align*}\n  \\E[Y&_{A_\\delta,M_{A_\\delta}} - Y_{,M_A}] = \\\\\n  &\\underbrace{\\E[Y_{\\color{red}{A_\\delta},\\color{blue}{M_{A_\\delta}}} -\n    Y_{\\color{red}{A_\\delta},\\color{blue}{M}}]}_{\\text{stochastic natural indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{A_\\delta},\\color{red}{M}} -\n    Y_{\\color{blue}{},\\color{red}{M}}]}_{\\text{stochastic natural direct effect}}\n\\end{align*}\\]can decompose total effect :\n\\[\\begin{align*}\n  \\E[Y&_{A_\\delta,M_{A_\\delta}} - Y_{,M_A}] = \\\\\n  &\\underbrace{\\E[Y_{\\color{red}{A_\\delta},\\color{blue}{M_{A_\\delta}}} -\n    Y_{\\color{red}{A_\\delta},\\color{blue}{M}}]}_{\\text{stochastic natural indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{A_\\delta},\\color{red}{M}} -\n    Y_{\\color{blue}{},\\color{red}{M}}]}_{\\text{stochastic natural direct effect}}\n\\end{align*}\\]","code":""},{"path":"stochastic.html","id":"identification-assumptions-3","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3.4 Identification assumptions","text":"Confounder assumptions:\n\\(\\indep Y_{,m} \\mid W\\)\n\\(M \\indep Y_{,m} \\mid W, \\)\n\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, \\)confounder \\(M\\rightarrow Y\\) affected \\(\\)Positivity assumptions:\n\\(g_\\delta(\\mid w)>0\\) \\(g(\\mid w)>0\\)\n\\(\\P(Z=z\\mid W=w)>0\\) \\(\\P(Z=z\\mid =,W=w)>0\\)\n\\(g_\\delta(\\mid w)>0\\) \\(g(\\mid w)>0\\)\\(\\P(Z=z\\mid W=w)>0\\) \\(\\P(Z=z\\mid =,W=w)>0\\)assumptions, stochastic effects identified followsThe indirect effect can identified follows\n\\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{}\\color{ForestGreen}{\\{\\E(Y\\mid =, W)-\\E(Y\\mid =, M, W)\\}}g_\\delta(\\mid W)}\\right]\n\\end{align*}\\]indirect effect can identified follows\n\\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{}\\color{ForestGreen}{\\{\\E(Y\\mid =, W)-\\E(Y\\mid =, M, W)\\}}g_\\delta(\\mid W)}\\right]\n\\end{align*}\\]direct effect can identified follows\n\\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{}\\color{ForestGreen}{\\{\\E(Y\\mid =, M, W) - Y\\}}g_\\delta(\\mid W)}\\right]\n\\end{align*}\\]direct effect can identified follows\n\\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{}\\color{ForestGreen}{\\{\\E(Y\\mid =, M, W) - Y\\}}g_\\delta(\\mid W)}\\right]\n\\end{align*}\\]Let’s dissect formula indirect effect R:Let’s dissect formula indirect effect R:First, fit regressions outcome \\((,W)\\) \\((M,,W)\\):Get predictions fixing \\(=\\) possible values \\(\\)Compute\n\\[\\color{ForestGreen}{\\{\\E(Y\\mid =, W)-\\E(Y\\mid =, M, W)\\}}\\]\nvalue \\(\\)Estimate propensity score \\(g(1\\mid w)\\) evaluate post-intervention\npropensity score \\(g_\\delta(1\\mid w)\\)post-intervention propensity scores look like?","code":"\nn <- 1e6\nw <- rnorm(n)\na <- rbinom(n, 1, plogis(1 + w))\nm <- rnorm(n, w + a)\ny <- rnorm(n, w + a + m)\nfit_y1 <- lm(y ~ m + a + w)\nfit_y2 <- lm(y ~ a + w)\npred_y1_a1 <- predict(fit_y1, newdata = data.frame(a = 1, m, w))\npred_y1_a0 <- predict(fit_y1, newdata = data.frame(a = 0, m, w))\npred_y2_a1 <- predict(fit_y2, newdata = data.frame(a = 1, w))\npred_y2_a0 <- predict(fit_y2, newdata = data.frame(a = 0, w))\npseudo_a1 <- pred_y2_a1 - pred_y1_a1\npseudo_a0 <- pred_y2_a0 - pred_y1_a0\npscore_fit <- glm(a ~ w, family = binomial())\npscore <- predict(pscore_fit, type = 'response')\n## How do the intervention vs observed propensity score compare\npscore_delta <- 2 * pscore / (2 * pscore + 1 - pscore)\nplot(pscore, pscore_delta, xlab = 'Observed prop. score',\n     ylab = 'Prop. score under intervention')\nabline(0, 1)"},{"path":"stochastic.html","id":"what-are-the-odds-of-exposure-under-intervention-vs-real-world","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3.5 What are the odds of exposure under intervention vs real world?","text":"Compute sum\n\\[\\color{Goldenrod}{\\sum_{}\\color{ForestGreen}{\\{\\E(Y\\mid =, W)-\\E(Y\\mid =, M, W)\\}}g_\\delta(\\mid W)}\\]average value indirect effectThe direct effect \n\\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{}\\color{ForestGreen}{\\{\\E(Y\\mid =, M, W) - Y\\}}g_\\delta(\\mid W)}\\right]\n\\end{align*}\\]direct effect \n\\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{}\\color{ForestGreen}{\\{\\E(Y\\mid =, M, W) - Y\\}}g_\\delta(\\mid W)}\\right]\n\\end{align*}\\]can computed asWhich can computed ","code":"\nodds <- (pscore_delta / (1 - pscore_delta)) / (pscore / (1 - pscore))\nsummary(odds)\nindirect <- pseudo_a1 * pscore_delta + pseudo_a0 * (1 - pscore_delta)\n## E[Y(Adelta) - Y(Adelta, M)]\nmean(indirect)\ndirect <- (pred_y1_a1 - y) * pscore_delta +\n       (pred_y1_a0 - y) * (1 - pscore_delta)\nmean(direct)"},{"path":"stochastic.html","id":"summary","chapter":"3 Stochastic Direct and Indirect Effects","heading":"3.6 Summary","text":"Stochastic ()direct effects\nRelax positivity assumption\nCan defined non-binary exposures\nrequire cross-world assumption\nRelax positivity assumptionCan defined non-binary exposuresDo require cross-world assumptionStill require absence intermediate confounders\n, compared NDE NIE, can design randomized study \nidentifiability assumptions hold, least principle\nversion effects can accomodate intermediate\nconfounders (Hejazi et al. 2020)\nR implementation released soon…stay tuned!\n, compared NDE NIE, can design randomized study \nidentifiability assumptions hold, least principleThere version effects can accomodate intermediate\nconfounders (Hejazi et al. 2020)R implementation released soon…stay tuned!","code":""},{"path":"estimandirl.html","id":"estimandirl","chapter":"4 How to choose an estimand: Real world example","heading":"4 How to choose an estimand: Real world example","text":"","code":""},{"path":"estimandirl.html","id":"comparative-effectivness-of-two-medications-for-opioid-use-disorder-oud","chapter":"4 How to choose an estimand: Real world example","heading":"4.1 Comparative effectivness of two medications for opioid use disorder (OUD)","text":"Motivation: Opposite overall treatment effects homeless versus\nnonhomeless participants.","code":""},{"path":"estimandirl.html","id":"getting-specific-about-the-question","chapter":"4 How to choose an estimand: Real world example","heading":"4.1.1 Getting specific about the question","text":"extent indirect effect mediators adherence, pain, \ndepressive symptoms explain differences treatment effects OUD relapse\nhomeless nonhomeless individuals?","code":""},{"path":"estimandirl.html","id":"what-estimand-do-we-want","chapter":"4 How to choose an estimand: Real world example","heading":"What estimand do we want?","text":"Can set \\(M=m\\) (.e., value) everyone?interested estimating indirect effects?\\(\\rightarrow\\) , controlled direct effect.intermediate confounder?Yes, ’s important.\\(\\rightarrow\\) , natural ()direct effects., ’re left interventional direct indirect effects.want estimate path treatment initiation (\\(Z\\))?Yes, , conditional versions effects.Estimands:\nDirect effect: \\(\\E(Y_{1,G_0} - Y_{0,G_0})\\)\nIndirect effect: \\(\\E(Y_{1,G_1} - Y_{1,G_0})\\)\nDirect effect: \\(\\E(Y_{1,G_0} - Y_{0,G_0})\\)Indirect effect: \\(\\E(Y_{1,G_1} - Y_{1,G_0})\\)\\(G_a\\) draw distribution \\(M_a\\mid W\\).Need incorporate multiple continuous mediators","code":""},{"path":"estimandirl.html","id":"what-if-the-positivity-assumption-paamid-w0-violated","chapter":"4 How to choose an estimand: Real world example","heading":"What if the positivity assumption \\(\\P(A=a\\mid W)>0\\) violated?","text":"\\(\\rightarrow\\) Can’t identify estimate effectsBut can estimate effect stochastic interventions, e.g., IPSIsTradeoff feasibility interpretation","code":""},{"path":"estimandirl.html","id":"what-if-the-exposure-variable-is-continuous","chapter":"4 How to choose an estimand: Real world example","heading":"What if the exposure variable is continuous?","text":"\\(\\rightarrow\\) effects defined binary exposuresBut can estimate effect stochastic interventionsWork progress (including upcoming R software)","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"preliminaries-on-semiparametric-estimation","chapter":"5 Preliminaries on semiparametric estimation","heading":"5 Preliminaries on semiparametric estimation","text":"","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"from-causal-to-statistical-quantities","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1 From causal to statistical quantities","text":"arrived identification formulas express quantities \ncare terms observable quantitiesThis required causal assumptions\nMany assumptions empirically unverifiable\nsaw example relax cross-world assumption, \ncost changing parameter interpretation\nrelax positivity assumption, also cost \nchanging parameter interpretation\nMany assumptions empirically unverifiableWe saw example relax cross-world assumption, \ncost changing parameter interpretationand relax positivity assumption, also cost \nchanging parameter interpretationThe resulting estimation problem can tackled using statistical\nassumptions various degrees strength\nassumptions verifiable (e.g., linear model)\nThus, unnecessary (except convenience)\nestimation approach use reduces reliance statistical\nassumptions\nassumptions verifiable (e.g., linear model)Thus, unnecessary (except convenience)estimation approach use reduces reliance statistical\nassumptions","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"computing-identification-formulas-if-you-know-the-true-distribution","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.1 Computing identification formulas if you know the true distribution","text":"mediation parameters consider can \nseen function joint probability distribution \\(O=(W,,Z,M,Y)\\)example, identifiability assumptions natural direct effect \nequal \n\\[\\begin{equation*}\n  \\psi(\\P) =  \\E[\\E\\{\\E(Y \\mid =1, M, W) - \\E(Y \\mid =0, M, W)\\mid =0,W\\}]\n\\end{equation*}\\]notation \\(\\psi(\\P)\\) implies parameter function \\(\\P\\)means can compute distribution \\(\\P\\)example, know true \\(\\P(W,,M,Y)\\), can comnpute true value\nparameter :\nComputing conditional expectation \\(\\E(Y\\mid =1,M=m,W=w)\\) \nvalues \\((m,w)\\)\nComputing probability \\(\\P(M=m\\mid =0,W=w)\\) values \\((m,w)\\)\nComputing probability \\(\\P(W=w)\\) values \\(w\\)\nComputing mean values \\((m,w)\\)\nComputing conditional expectation \\(\\E(Y\\mid =1,M=m,W=w)\\) \nvalues \\((m,w)\\)Computing probability \\(\\P(M=m\\mid =0,W=w)\\) values \\((m,w)\\)Computing probability \\(\\P(W=w)\\) values \\(w\\)Computing mean values \\((m,w)\\)","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"estimating-identification-formulas","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.2 Estimating identification formulas","text":"compute true value know true\ndistribution \\(\\P\\)exactly R examples beforeBut can use logic estimation:\nFit regression estimate, say \\(\\hat\\E(Y\\mid =1,M=m,W=w)\\)\nFit regression estimate, say \\(\\hat\\P(M=m\\mid =0,W=w)\\)\nEstimate \\(\\P(W=w)\\) empirical distribution\nEvaluate\n\\[\\begin{equation*}\n  \\psi(\\hat\\P) =  \\hat\\E[\\hat\\E\\{\\hat\\E(Y \\mid =1, M, W) -\n  \\hat\\E(Y \\mid =0, M, W)\\mid =0,W\\}]\n\\end{equation*}\\]\nFit regression estimate, say \\(\\hat\\E(Y\\mid =1,M=m,W=w)\\)Fit regression estimate, say \\(\\hat\\P(M=m\\mid =0,W=w)\\)Estimate \\(\\P(W=w)\\) empirical distributionEvaluate\n\\[\\begin{equation*}\n  \\psi(\\hat\\P) =  \\hat\\E[\\hat\\E\\{\\hat\\E(Y \\mid =1, M, W) -\n  \\hat\\E(Y \\mid =0, M, W)\\mid =0,W\\}]\n\\end{equation*}\\]known g-computation estimator","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"how-can-g-estimation-be-implemented-in-practice","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.3 How can g-estimation be implemented in practice?","text":"two possible ways g-computation estimation:\nUsing parametric models regressions\nUsing flexible data-adaptive regression (aka machine learning)\nUsing parametric models regressionsUsing flexible data-adaptive regression (aka machine learning)","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"pros-and-cons-of-parametric-models","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.4 Pros and cons of parametric models","text":"Pros:\nEasy understand\nEase implementation (standard regression software)\nCan use Delta method bootstrap computation standard errors\nEasy understandEase implementation (standard regression software)Can use Delta method bootstrap computation standard errorsCons:\nUnless \\(W\\) \\(M\\) contain categorical variables, easy\nmisspecify models\ncan introduce sizable bias estimators\nUnless \\(W\\) \\(M\\) contain categorical variables, easy\nmisspecify modelsThis can introduce sizable bias estimators","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"an-example-of-the-bias-of-a-g-computation-estimator-of-the-natural-direct-effect","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.5 An example of the bias of a g-computation estimator of the natural direct effect","text":"following R chunk provides simulation code exemplify bias \ng-computation estimator simple situationThis yields true NDE value ofLet’s perform simulation draw 1000 datasets distribution, compute g-computation estimator based onThe bias also affects confidence intervals:","code":"\nmean_y <- function(m, a, w) abs(w) + a * m\nmean_m <- function(a, w) plogis(w^2 - a)\npscore <- function(w) plogis(1 - abs(w))\nw_big <- runif(1e6, -1, 1)\ntrueval <- mean((mean_y(1, 1, w_big) - mean_y(1, 0, w_big)) *\n  mean_m(0, w_big) + (mean_y(0, 1, w_big) - mean_y(0, 0, w_big)) *\n    (1 - mean_m(0, w_big)))\nprint(trueval)\ngcomp <- function(y, m, a, w) {\n  lm_y <- lm(y ~ m + a + w)\n  pred_y1 <- predict(lm_y, newdata = data.frame(a = 1, m = m, w = w))\n  pred_y0 <- predict(lm_y, newdata = data.frame(a = 0, m = m, w = w))\n  pseudo <- pred_y1 - pred_y0\n  lm_pseudo <- lm(pseudo ~ a + w)\n  pred_pseudo <- predict(lm_pseudo, newdata = data.frame(a = 0, w = w))\n  estimate <- mean(pred_pseudo)\n  return(estimate)\n}\nestimate <- numeric(1000)\nfor (i in 1:1000) {\n  n <- 1000\n  w <- runif(n, -1, 1)\n  a <- rbinom(n, 1, pscore(w))\n  m <- rbinom(n, 1, mean_m(a, w))\n  y <- rnorm(n, mean_y(m, a, w))\n\n  estimate[i] <- gcomp(y, m, a, w)\n}\n\nhist(estimate)\nabline(v = trueval, col = \"red\", lwd = 4)\ncis <- cbind(\n  estimate - qnorm(0.975) * sd(estimate),\n  estimate + qnorm(0.975) * sd(estimate)\n)\n\nord <- order(rowSums(cis))\nlower <- cis[ord, 1]\nupper <- cis[ord, 2]\ncurve(trueval + 0 * x,\n  ylim = c(0, 1), xlim = c(0, 1001), lwd = 2, lty = 3, xaxt = \"n\",\n  xlab = \"\", ylab = \"Confidence interval\", cex.axis = 1.2, cex.lab = 1.2\n)\nfor (i in 1:1000) {\n  clr <- rgb(0.5, 0, 0.75, 0.5)\n  if (upper[i] < trueval || lower[i] > trueval) clr <- rgb(1, 0, 0, 1)\n  points(rep(i, 2), c(lower[i], upper[i]), type = \"l\", lty = 1, col = clr)\n}\ntext(450, 0.10, \"n=1000 repetitions = 1000 \", cex = 1.2)\ntext(450, 0.01, paste0(\n  \"Coverage probability = \",\n  mean(lower < trueval & trueval < upper), \"%\"\n), cex = 1.2)"},{"path":"preliminaries-on-semiparametric-estimation.html","id":"pros-and-cons-of-g-computation-with-data-adaptive-regression","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.1.6 Pros and cons of g-computation with data-adaptive regression","text":"Pros:\nEasy understand\nAlleviate model-misspecification bias\nEasy understandAlleviate model-misspecification biasCons:\nMight harder implement depending regression procedures used\ngeneral approaches computation standard errors confidence\nintervals\nexample, bootstrap guaranteed work, known \nfail cases\nMight harder implement depending regression procedures usedNo general approaches computation standard errors confidence\nintervalsFor example, bootstrap guaranteed work, known \nfail cases","code":""},{"path":"preliminaries-on-semiparametric-estimation.html","id":"semiparametric-estimation-or-correcting-the-bias-of-g-computation-estimators","chapter":"5 Preliminaries on semiparametric estimation","heading":"5.2 Semiparametric estimation (or correcting the bias of g-computation estimators)","text":"G-computation estimation data-adaptive regression offers incorrect\nbias/variance trade-offIt accepts bias necessaryThe bias g-computation estimator may corrected follows:\n\\[\\begin{equation*}\n  \\psi(\\hat \\P) + \\frac{1}{n}\\sum_{=1}^n D(O_i)\n\\end{equation*}\\]\nfunction \\(D(O_i)\\) dataThe function \\(D(O)\\) called efficient influence function (EIF)EIF must found case--case basis parameter \\(\\psi(\\P)\\)example, estimating standardized mean \\(\\psi(\\P)=\\E[\\E(Y\\mid =1, W)]\\), \n\\[\\begin{equation*}\n  D(O) = \\frac{}{\\hat \\P(=1\\mid W)}[Y - \\hat\\E(Y\\mid =1, W)] +\n  \\hat\\E(Y\\mid =1, W) - \\psi(\\hat\\P)\n\\end{equation*}\\]EIF found using distributional analogue Taylor expansionIn workshop omit specific form \\(D(O)\\) \nparameters useBut estimators discuss implement R packages based \nEIFsAnd specific form EIF may found papers referencesNote: bias correction may additional problem returning\nparameter estimates outside natural bounds. E.g., probabilities greater \none. solution (discussed workshop) targeted minimum\nloss based estimation.","code":""},{"path":"using-the-eif-to-construct-an-estimator-the-case-of-the-natural-direct-effect.html","id":"using-the-eif-to-construct-an-estimator-the-case-of-the-natural-direct-effect","chapter":"6 Using the EIF to construct an estimator: the case of the natural direct effect","heading":"6 Using the EIF to construct an estimator: the case of the natural direct effect","text":"","code":""},{"path":"using-the-eif-to-construct-an-estimator-the-case-of-the-natural-direct-effect.html","id":"natural-direct-effect","chapter":"6 Using the EIF to construct an estimator: the case of the natural direct effect","heading":"6.1 Natural direct effect","text":"Recall:Assuming binary \\(\\), define natural direct effect : \\[NDE = E(Y_{1,M_{0}} - Y_{0,M_{0}}),\\]Assuming binary \\(\\), define natural direct effect : \\[NDE = E(Y_{1,M_{0}} - Y_{0,M_{0}}),\\]natural indirect effect : \\[NIE = E(Y_{1,M_{1}} - Y_{1,M_{0}}).\\]natural indirect effect : \\[NIE = E(Y_{1,M_{1}} - Y_{1,M_{0}}).\\]observed data \\(O=(W, , M, Y)\\)observed data \\(O=(W, , M, Y)\\)SCM represented DAG following causal models:\n\\[\\begin{align*}\n  W & = f_W(U_W)\\\\\n  & = f_A(W, U_A)\\\\\n  M & = f_M(W, , U_M)\\\\\n  Y & = f_Y(W, , M, U_Y),\n\\end{align*}\\]\n\\((U_W, U_A,U_M, U_Y)\\) exogenous random errors.assume\n- \\(\\) single binary randomized treatment (thus \\(= f_A(U_A)\\))\n- \\(M\\) single binary mediator\n- restrictions distribution \\(W\\) \\(Y\\)Recall need assume following identify caual effects\nobserved data:\\(\\indep Y_{,m} \\mid W\\)\\(M \\indep Y_{,m} \\mid W, \\)\\(\\indep M_a \\mid W\\)\\(M_0 \\indep Y_{1,m} \\mid W\\)positivity assumptionsThen, NDE identified \n\\[\\begin{equation*}\n    \\psi(\\P) =  \\E[\\E\\{\\E(Y \\mid =1, M, W) - \\E(Y \\mid =0, M, W)\\mid =0,W\\}]\n  \\end{equation*}\\]","code":""},{"path":"using-the-eif-to-construct-an-estimator-the-case-of-the-natural-direct-effect.html","id":"the-efficient-influence-function-for-the-nde","chapter":"6 Using the EIF to construct an estimator: the case of the natural direct effect","heading":"6.1.1 The efficient influence function for the NDE","text":"illustration, first present construct estimator \nNDE uses EIF ``hand’’parameters, teach use packages medoutcon\nmedshiftFirst, need introduce notation describe EIF NDELet \\(Q(M, W)\\) denote \\(\\E(Y\\mid =1, M, W) - \\E(Y\\mid =0, M, W)\\)Let \\(Q(M, W)\\) denote \\(\\E(Y\\mid =1, M, W) - \\E(Y\\mid =0, M, W)\\)can now introduce EIF:\n\\[\\begin{align*}\n  D(O) &= \\color{ForestGreen}{\\bigg\\{ \\frac{(=1)}{\\P(=1\\mid W)}\\frac{\\P(M\\mid =0,W)}{\\P(M\\mid =1,W)} -\n    \\frac{(=0)}{\\P(=0\\mid W)}\\bigg\\}} \\times [Y-\\E(Y\\mid ,M,W)]  \\\\\n  &+ \\frac{(=0)}{\\P(=0\\mid W)}\\big\\{Q(M,W) - \\E[Q(M,W) | W,=0] \\big\\}\\\\\n  &+ \\E[Q(M,W) | W,=0] - \\psi(\\P)\n\\end{align*}\\]can now introduce EIF:\n\\[\\begin{align*}\n  D(O) &= \\color{ForestGreen}{\\bigg\\{ \\frac{(=1)}{\\P(=1\\mid W)}\\frac{\\P(M\\mid =0,W)}{\\P(M\\mid =1,W)} -\n    \\frac{(=0)}{\\P(=0\\mid W)}\\bigg\\}} \\times [Y-\\E(Y\\mid ,M,W)]  \\\\\n  &+ \\frac{(=0)}{\\P(=0\\mid W)}\\big\\{Q(M,W) - \\E[Q(M,W) | W,=0] \\big\\}\\\\\n  &+ \\E[Q(M,W) | W,=0] - \\psi(\\P)\n\\end{align*}\\]Estimating \\(\\P(M\\mid , W)\\) really hard problem \\(M\\) \nhigh-dimensional. , since ratio conditional\ndensitities, can reparamterize using Bayes rule get something \neasier compute:Estimating \\(\\P(M\\mid , W)\\) really hard problem \\(M\\) \nhigh-dimensional. , since ratio conditional\ndensitities, can reparamterize using Bayes rule get something \neasier compute:\\[\\begin{equation*}\n  \\frac{\\P(M\\mid =0,W)}{\\P(M\\mid =1,W)} = \\frac{\\P(= 0 \\mid M, W) \\P(=1\n  \\mid W)}{\\P(= 1 \\mid M, W)\\P(=0 \\mid W)}.\n\\end{equation*}\\]Thus can change expression EIF bit follows. First, \nnotation useful later:Let \\(g(\\mid w)\\) denote \\(\\P(=\\mid W=w)\\)Let \\(e(\\mid m, w)\\) denote \\(\\P(=\\mid M=m, W=w)\\)Let \\(b(, m, w)\\) denote \\(\\E(Y\\mid =, M=m, W=w)\\)EIF \\[\\begin{align*}\n    D(O) &= \\color{ForestGreen}{\\bigg\\{ \\frac{(=1)}{g(0\\mid W)}\\frac{e(0\\mid M,W)}{e(1\\mid M,W)} -\n      \\frac{(=0)}{g(0\\mid W)}\\bigg\\}} \\times [Y-b(,M,W)]  \\\\\n    &+ \\frac{(=0)}{g(0\\mid W)}\\big\\{Q(M,W) - \\E[Q(M,W) | W,=0] \\big\\}\\\\\n    &+ \\E[Q(M,W) | W,=0] - \\psi(\\P)\n\\end{align*}\\]","code":""},{"path":"using-the-eif-to-construct-an-estimator-the-case-of-the-natural-direct-effect.html","id":"how-to-compute-the-one-step-estimator-akin-to-augmented-ipw","chapter":"6 Using the EIF to construct an estimator: the case of the natural direct effect","heading":"6.1.2 How to compute the one-step estimator (akin to Augmented IPW)","text":"First generate data:Recall one-step estimator defined bias-corrected\ng-computation estimator:\n\\[\\begin{equation*}\n  \\psi(\\hat \\P) + \\frac{1}{n}\\sum_{=1}^n D(O;\\hat \\P_i)\n\\end{equation*}\\]Can computed following steps:Fit models \\(g(\\mid w)\\), \\(e(\\mid m, w)\\), \\(b(, m, w)\\)\nexample use Generalized Additive Models [CITE] \ntractability\napplied settings recommend using ensemble data-adaptive\nregression algorithms, Super Learner [CITE]\nexample use Generalized Additive Models [CITE] \ntractabilityIn applied settings recommend using ensemble data-adaptive\nregression algorithms, Super Learner [CITE]Compute predictions \\(g(1\\mid w)\\), \\(g(0\\mid w)\\), \\(e(1\\mid m, w)\\),\n\\(e(0\\mid m, w)\\),\\(b(1, m, w)\\), \\(b(0, m, w)\\), \\(b(, m, w)\\)Compute \\(Q(M, W)\\), fit model \\(\\E[Q(M,W) | W,]\\), predict \\(=0\\)Estimate weights\n\\[\\begin{equation*}\n  \\bigg\\{ \\frac{(=1)}{g(0\\mid W)}\\frac{e(0\\mid M,W)}{e(1\\mid M,W)} -\n   \\frac{(=0)}{g(0\\mid W)}\\bigg\\}\n  \\end{equation*}\\]\nusing predictions:Compute uncentered EIF:one step estimator mean uncentered EIF","code":"\nmean_y <- function(m, a, w) abs(w) + a * m\nmean_m <- function(a, w)plogis(w^2 - a)\npscore <- function(w) plogis(1 - abs(w))\n\nw_big <- runif(1e6, -1, 1)\ntrueval <- mean((mean_y(1, 1, w_big) - mean_y(1, 0, w_big)) * mean_m(0, w_big)\n                + (mean_y(0, 1, w_big) - mean_y(0, 0, w_big)) *\n                  (1 - mean_m(0, w_big)))\n\nn <- 1000\nw <- runif(n, -1, 1)\na <- rbinom(n, 1, pscore(w))\nm <- rbinom(n, 1, mean_m(a, w))\ny <- rnorm(n, mean_y(m, a, w))library(mgcv)\n## fit model for E(Y | A, W)\nb_fit <- gam(y ~ m:a + s(w, by = a)\n## fit model for P(A = 1 | M, W)\ne_fit <- gam(a ~ m + w + s(w, by = m), family = binomial)\n## fit model for P(A = 1 | W)\ng_fit <- gam(a ~ w, family = binomial)\n## Compute P(A = 1 | W)\ng1_pred <- predict(g_fit, type = 'response')\n## Compute P(A = 0 | W)\ng0_pred <- 1 - g1_pred\n## Compute P(A = 1 | M, W)\ne1_pred <- predict(e_fit, type = 'response')\n## Compute P(A = 0 | M, W)\ne0_pred <- 1 - e1_pred\n## Compute E(Y | A = 1, M, W)\nb1_pred <- predict(b_fit, newdata = data.frame(a = 1, m, w))\n## Compute E(Y | A = 0, M, W)\nb0_pred <- predict(b_fit, newdata = data.frame(a = 0, m, w))\n## Compute E(Y | A, M, W)\nb_pred  <- predict(b_fit)\n## Compute Q(M, W)\npseudo <- b1_pred - b0_pred\n## Fit model for E[Q(M, W) | A, W]\nq_fit <- gam(pseudo ~ a + w + s(w, by = a))\n## Compute E[Q(M, W) | A = 0, W]\nq_pred <- predict(q_fit, newdata = data.frame(a = 0, w = w))\nweights <- a / g0_pred * e0_pred / e1_pred - (1 - a) / g0_pred\neif <- weights * (y - b_pred) + (1 - a) / g0_pred * (pseudo - q_pred) +\n  q_pred\n## One-step estimator\nmean(eif)"},{"path":"using-the-eif-to-construct-an-estimator-the-case-of-the-natural-direct-effect.html","id":"performance-of-the-one-step-estimator-in-a-small-simulation-study","chapter":"6 Using the EIF to construct an estimator: the case of the natural direct effect","heading":"6.1.3 Performance of the one-step estimator in a small simulation study","text":"First, create wrapper around estimatorLet us first examine biasThe true value :Bias simulationAnd now confidence intervals:","code":"\none_step <- function(y, m, a, w) {\n  b_fit <- gam(y ~ m:a + s(w, by = a))\n  e_fit <- gam(a ~ m + w + s(w, by = m), family = binomial)\n  g_fit <- gam(a ~ w, family = binomial)\n  g1_pred <- predict(g_fit, type = 'response')\n  g0_pred <- 1 - g1_pred\n  e1_pred <- predict(e_fit, type = 'response')\n  e0_pred <- 1 - e1_pred\n  b1_pred <- predict(b_fit, newdata = data.frame(a = 1, m, w),\n                 type = 'response')\n  b0_pred <- predict(b_fit, newdata = data.frame(a = 0, m, w),\n                     type = 'response')\n  b_pred  <- predict(b_fit, type = 'response')\n  pseudo <- b1_pred - b0_pred\n  q_fit <- gam(pseudo ~ a + w + s(w, by = a))\n  q_pred <- predict(q_fit, newdata = data.frame(a = 0, w = w))\n  weights <- a / g0_pred * e0_pred / e1_pred - (1 - a) / g0_pred\n  eif <- weights * (y - b_pred) + (1 - a) / g0_pred *\n    (pseudo - q_pred) + q_pred\n  return(mean(eif))\n}\nw_big <- runif(1e6, -1, 1)\ntrueval <- mean((mean_y(1, 1, w_big) - mean_y(1, 0, w_big)) * mean_m(0, w_big) +\n  (mean_y(0, 1, w_big) - mean_y(0, 0, w_big)) * (1 - mean_m(0, w_big)))\nprint(trueval)\nestimate <- numeric(1000)\nfor (i in 1:1000) {\n  n <- 1000\n  w <- runif(n, -1, 1)\n  a <- rbinom(n, 1, pscore(w))\n  m <- rbinom(n, 1, mean_m(a, w))\n  y <- rnorm(n, mean_y(m, a, w))\n\n  estimate[i] <- one_step(y, m, a, w)\n}\n\nhist(estimate)\nabline(v = trueval, col = \"red\", lwd = 4)\ncis <- cbind(\n  estimate - qnorm(0.975) * sd(estimate),\n  estimate + qnorm(0.975) * sd(estimate)\n)\n\nord <- order(rowSums(cis))\nlower <- cis[ord, 1]\nupper <- cis[ord, 2]\ncurve(trueval + 0 * x,\n  ylim = c(0, 1), xlim = c(0, 1001), lwd = 2, lty = 3, xaxt = \"n\",\n  xlab = \"\", ylab = \"Confidence interval\", cex.axis = 1.2, cex.lab = 1.2\n)\nfor (i in 1:1000) {\n  clr <- rgb(0.5, 0, 0.75, 0.5)\n  if (upper[i] < trueval || lower[i] > trueval) clr <- rgb(1, 0, 0, 1)\n  points(rep(i, 2), c(lower[i], upper[i]), type = \"l\", lty = 1, col = clr)\n}\ntext(450, 0.10, \"n=1000 repetitions = 1000 \", cex = 1.2)\ntext(450, 0.01, paste0(\n  \"Coverage probability = \",\n  mean(lower < trueval & trueval < upper), \"%\"\n), cex = 1.2)"},{"path":"estimating-indirect-effects-with-r-packages.html","id":"estimating-indirect-effects-with-r-packages","chapter":"7 Estimating (in)direct effects with R packages","heading":"7 Estimating (in)direct effects with R packages","text":"","code":""},{"path":"estimating-indirect-effects-with-r-packages.html","id":"medshift-stochastic-indirect-effects","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.1 medshift: Stochastic (in)direct effects","text":"interested assessing population intervention direct effect \npopulation intervention indirect effect, based effect decomposition\npopulation intervention effect introduced Dı́az Hejazi (2020).proceed, ’ll use running example simple data set \nobservational study relationship BMI kids behavior,\ndistributed part mma R package \nCRAN. First, let’s load packages\n’ll using set seed; , load data set take quick look\nitThe documentation data set describes “database obtained \nLouisiana State University Health Sciences Center, New Orleans, Dr. Richard\nScribner. explored relationship BMI kids behavior \nsurvey children, teachers parents Grenada 2014. data set\nincludes 691 observations 15 variables.”Unfortunately, data set contains observations missing values. \nunrelated object analysis, ’ll simply remove \ntime . Note real data analysis, might consider strategies\nfully make observed data, perhaps imputing missing values. now,\nsimply remove incomplete observations, resulting data set fewer\nobservations much structure original:analysis observational data set, focus effect \nparticipating sports team (sports) BMI children (bmi), taking\nseveral related covariates mediators (snack, exercises, overweigh) \ncollected covariates potential confounders. Considering NPSEM,\nseparate observed variables data set corresponding\nnodes followsFinally, analysis, consider incremental propensity score\nintervention (IPSI), first proposed (???), wherein \nodds participating sports team modulated fixed amount\n(\\(0 \\leq \\delta \\leq \\infty\\)) individual. intervention may \ninterpreted effect school program motivates children \nparticipate sports teams. exemplify approach, postulate \nmotivational intervention triples odds participating sports\nteam individual:easily incorporate ensemble machine learning estimation procedure,\nrely facilities provided sl3 R\npackage (???). complete guide using\nsl3 R package, consider consulting https://tlverse.org/sl3, \nhttps://tlverse.org (https://github.com/tlverse) tlverse\necosystem, sl3 major part. construct ensemble learner\nusing handful popular machine learning algorithms ","code":"\n# preliminaries\nlibrary(data.table)\nlibrary(dplyr)\nlibrary(sl3)\nlibrary(medshift)\nlibrary(mma)\nset.seed(429153)\n\n# load and examine data\ndata(weight_behavior)\ndim(weight_behavior)\nhead(weight_behavior)\nY <- weight_behavior_complete$bmi\nA <- weight_behavior_complete$sports\nZ <- weight_behavior_complete %>%\n  select(snack, exercises, overweigh)\nW <- weight_behavior_complete %>%\n  select(\n    age, sex, race, numpeople, car, gotosch, tvhours, cmpthours,\n    cellhours, sweat\n  )\ndelta_shift_ipsi <- 3\n# SL learners used for continuous data (the nuisance parameter M)\nxgb_contin_lrnr <- Lrnr_xgboost$new(nrounds = 50, objective = \"reg:linear\")\nenet_contin_lrnr <- Lrnr_glmnet$new(\n  alpha = 0.5, family = \"gaussian\",\n  nfolds = 3\n)\nlasso_contin_lrnr <- Lrnr_glmnet$new(\n  alpha = 1, family = \"gaussian\",\n  nfolds = 3\n)\nfglm_contin_lrnr <- Lrnr_glm_fast$new(family = gaussian())\ncontin_lrnr_lib <- Stack$new(\n  enet_contin_lrnr, lasso_contin_lrnr,\n  fglm_contin_lrnr, xgb_contin_lrnr\n)\nsl_contin_lrnr <- Lrnr_sl$new(\n  learners = contin_lrnr_lib,\n  metalearner = Lrnr_nnls$new()\n)\n\n# SL learners used for binary data (nuisance parameters G and E in this case)\nxgb_binary_lrnr <- Lrnr_xgboost$new(nrounds = 50, objective = \"reg:logistic\")\nenet_binary_lrnr <- Lrnr_glmnet$new(\n  alpha = 0.5, family = \"binomial\",\n  nfolds = 3\n)\nlasso_binary_lrnr <- Lrnr_glmnet$new(\n  alpha = 1, family = \"binomial\",\n  nfolds = 3\n)\nfglm_binary_lrnr <- Lrnr_glm_fast$new(family = binomial())\nbinary_lrnr_lib <- Stack$new(\n  enet_binary_lrnr, lasso_binary_lrnr,\n  fglm_binary_lrnr, xgb_binary_lrnr\n)\nlogistic_metalearner <- make_learner(\n  Lrnr_solnp,\n  metalearner_logistic_binomial,\n  loss_loglik_binomial\n)\nsl_binary_lrnr <- Lrnr_sl$new(\n  learners = binary_lrnr_lib,\n  metalearner = logistic_metalearner\n)"},{"path":"estimating-indirect-effects-with-r-packages.html","id":"decomposing-the-population-intervention-effect","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.1.1 Decomposing the population intervention effect","text":"may decompose population intervention effect (PIE) terms \npopulation intervention direct effect (PIDE) population\nintervention indirect effect (PIIE):\n\\[\\begin{equation*}\n  \\overbrace{\\mathbb{E}\\{Y(A_\\delta, Z(A_\\delta)) -\n    Y(A_\\delta, Z)\\}}^{\\text{PIIE}} +\n    \\overbrace{\\mathbb{E}\\{Y(A_\\delta, Z) - Y(, Z)\\}}^{\\text{PIDE}}.\n\\end{equation*}\\]decomposition PIE sum population intervention direct\nindirect effects interpretation analogous corresponding\nstandard decomposition average treatment effect. sequel, \ncompute components direct indirect effects using\nappropriate estimators followsFor \\(\\mathbb{E}\\{Y(, Z)\\}\\), sample mean \\(\\frac{1}{n}\\sum_{=1}^n Y_i\\) \nsufficient;\\(\\mathbb{E}\\{Y(A_{\\delta}, Z)\\}\\), efficient one-step estimator \neffect joint intervention altering exposure mechanism \nmediation mechanism, proposed Dı́az Hejazi (2020); ,\\(\\mathbb{E}\\{Y(A_{\\delta}, Z_{A_{\\delta}})\\}\\), efficient one-step\nestimator effect joint intervention altering exposure\nmediation mechanisms, proposed (???) \nimplemented npcausal R\npackage.","code":""},{"path":"estimating-indirect-effects-with-r-packages.html","id":"estimating-the-effect-decomposition-term","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.1.2 Estimating the effect decomposition term","text":"given Dı́az Hejazi (2020), statistical functional identifying \ndecomposition term appears PIDE PIIE\n\\(\\mathbb{E}\\{Y(A_{\\delta}, Z)\\}\\), corresponds altering exposure\nmechanism keeping mediation mechanism fixed, \n\\[\\begin{equation*}\n  \\theta_0(\\delta) = \\int m_0(, z, w) g_{0,\\delta}(\\mid w) p_0(z, w)\n    d\\nu(, z, w),\n\\end{equation*}\\]\none-step estimator available. corresponding efficient\ninfluence function (EIF) respect nonparametric model \\(\\mathcal{M}\\)\n\\(D_{\\eta,\\delta}(o) = D^Y_{\\eta,\\delta}(o) + D^A_{\\eta,\\delta}(o) + D^{Z,W}_{\\eta,\\delta}(o) - \\theta(\\delta)\\). \none-step estimator may computed using EIF estimating equation, making use\ncross-fitting (???; ???) circumvent \nneed entropy conditions (.e., Donsker class restrictions). resultant\nestimator \n\\[\\begin{equation*}\n  \\hat{\\theta}(\\delta) = \\frac{1}{n} \\sum_{= 1}^n D_{\\hat{\\eta}_{j()},\n  \\delta}(O_i) = \\frac{1}{n} \\sum_{= 1}^n \\left\\{ D^Y_{\\hat{\\eta}_{j()},\n  \\delta}(O_i) + D^A_{\\hat{\\eta}_{j()}, \\delta}(O_i) +\n  D^{Z,W}_{\\hat{\\eta}_{j()}, \\delta}(O_i) \\right\\},\n\\end{equation*}\\]\nimplemented medshift R package. make use \nimplementation estimate \\(\\mathbb{E}\\{Y(A_{\\delta}, Z)\\}\\) via one-step\nestimator \\(\\hat{\\theta}(\\delta)\\) ","code":"\n# let's compute the parameter where A (but not Z) are shifted\ntheta_eff <- medshift(\n  W = W, A = A, Z = Z, Y = Y,\n  delta = delta_shift_ipsi,\n  g_learners = sl_binary_lrnr,\n  e_learners = sl_binary_lrnr,\n  m_learners = sl_contin_lrnr,\n  phi_learners = Lrnr_hal9001$new(),\n  estimator = \"onestep\",\n  estimator_args = list(cv_folds = 3)\n)\nsummary(theta_eff)"},{"path":"estimating-indirect-effects-with-r-packages.html","id":"estimating-the-direct-effect","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.1.3 Estimating the direct effect","text":"Recall , based decomposition outlined previously, population\nintervention direct effect may denoted \\(\\beta_{\\text{PIDE}}(\\delta) = \\theta_0(\\delta) - \\mathbb{E}Y\\). Thus, estimator PIDE,\n\\(\\hat{\\beta}_{\\text{PIDE}}(\\delta)\\) may expressed composition \nestimators constituent parameters:\n\\[\\begin{equation*}\n  \\hat{\\beta}_{\\text{PIDE}}({\\delta}) = \\hat{\\theta}(\\delta) -\n  \\frac{1}{n} \\sum_{= 1}^n Y_i.\n\\end{equation*}\\]Based , may construct estimator PIDE using quantities\nalready computed. convenience function applies simple delta method\nrequired case linear contrast two constituent\nparameters:convenience function hand, ’ll construct extract \nnecessary components existing objects simply apply function:","code":"\n# convenience function to compute inference via delta method: EY1 - EY0\nlinear_contrast <- function(params, eifs, ci_level = 0.95) {\n  # bounds for confidence interval\n  ci_norm_bounds <- c(-1, 1) * abs(stats::qnorm(p = (1 - ci_level) / 2))\n  param_est <- params[[1]] - params[[2]]\n  eif <- eifs[[1]] - eifs[[2]]\n  se_eif <- sqrt(var(eif) / length(eif))\n  param_ci <- param_est + ci_norm_bounds * se_eif\n  # parameter and inference\n  out <- c(param_ci[1], param_est, param_ci[2])\n  names(out) <- c(\"lwr_ci\", \"param_est\", \"upr_ci\")\n  return(out)\n}\n# parameter estimates and EIFs for components of direct effect\nEY <- mean(Y)\neif_EY <- Y - EY\nparams_de <- list(theta_eff$theta, EY)\neifs_de <- list(theta_eff$eif, eif_EY)\n\n# direct effect = EY - estimated quantity\nde_est <- linear_contrast(params_de, eifs_de)\nde_est"},{"path":"estimating-indirect-effects-with-r-packages.html","id":"medoutcon-naturalinterventional-effects","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2 medoutcon: Natural/Interventional Effects","text":"exposure interest often affects outcome directly, indirectly \nmediation intermediate variables. Identifying quantifying \nmechanisms underlying causal effects increasingly popular endeavor \npublic health, medicine, social sciences, knowledge \nmechanisms can improve understanding treatments can \neffective. mechanistic knowledge may arguably even important \ncases treatments result unanticipated ineffective even harmful\neffects.Traditional techniques mediation analysis fare poorly face \nintermediate confounding. Classical parameters like natural ()direct\neffects face lack identifiability cases mediator-outcome (.e.,\nintermediate) confounders affected exposure complicate relationship\nexposure, mediators, outcome. (???) provide \ntheoretical computational study properties newly developed\ninterventional ()direct effect estimands within non-parametric statistical\nmodel. Among contributions, (???)derive efficient influence function (EIF), key object \nsemiparametric efficiency theory;use EIF develop two asymptotically optimal, non-parametric estimators,\ncapable leveraging machine learning estimation \nnuisance parameters; andpresent theoretical conditions proposed estimators \nconsistent, multiply robust, efficient.","code":""},{"path":"estimating-indirect-effects-with-r-packages.html","id":"problem-setup-and-notation","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2.1 Problem Setup and Notation","text":"problem addressed work (???) may represented\nfollowing nonparametric structural equation model (NPSEM):\n\\[\\begin{align*}\n  W &= f_W(U_W); = f_A(W, U_A); Z=f_Z(W, , U_Z);\\\\ \\nonumber\n  M &= f_M(W, , Z, U_M); Y = f_Y(W, , Z, M, U_Y).\n\\end{align*}\\]\nNPSEM, \\(W\\) denotes vector observed pre-treatment covariates, \\(\\)\ndenotes categorical treatment variable, \\(Z\\) denotes intermediate confounder\naffected treatment, \\(M\\) denotes (possibly multivariate) mediator, \\(Y\\)\ndenotes continuous binary outcome. vector exogenous factors\n\\(U=(U_W,U_A,U_Z,U_M,U_Y)\\), functions \\(f\\), assumed deterministic \nunknown. Importantly, NPSEM encodes time-ordering variables\nallows evaluation counterfactual quantities defined intervening \nset nodes NPSEM. observed data unit can represented \nrandom variable \\(O = (W, , Z, M, Y)\\); consider access \\(O_1, \\ldots, O_n\\),\nsample \\(n\\) ..d. observations \\(O\\).(???) additionally define following parameterizations,\nfamiliarity useful using medoutcon R\npackage. particular, authors\ndefine \\(g(\\mid w)\\) probability mass function \\(= \\) conditional \n\\(W = w\\) use \\(h(\\mid m, w)\\) denote probability mass function \\(= \\) conditional \\((M, W) = (m, w)\\). , (???) use\n\\(b(, z, m, w)\\) denote outcome regression function \\(\\mathbb{E}(Y \\mid = , Z = z, M = m, W = w)\\), well \\(q(z \\mid ,w)\\) \\(r(z \\mid , m, w)\\)\ndenote corresponding conditional densities \\(Z\\).","code":""},{"path":"estimating-indirect-effects-with-r-packages.html","id":"interventional-indirect-effects-1","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2.2 Interventional (In)Direct Effects","text":"(???) define total effect \\(\\) \\(Y\\) terms \ncontrast two user-supplied values \\(', ^{\\star} \\\\mathcal{}\\).\nExamination NPSEM reveals four paths involved \neffect, namely \\(\\rightarrow Y\\), \\(\\rightarrow M \\rightarrow Y\\), \\(\\rightarrow Z \\rightarrow Y\\), \\(\\rightarrow Z \\rightarrow M \\rightarrow Y\\).\nMediation analysis classically considered natural direct effect (NDE)\nnatural indirect effect (NIE), defined \n\\(\\mathbb{E}_c(Y_{', M_{^{\\star}}} - Y_{^{\\star}, M_{^{\\star}}})\\) \n\\(\\mathbb{E}_c(Y_{',M_{'}} - Y_{',M_{^{\\star}}})\\), respectively. natural\ndirect effect measures effect paths involving mediator\n(\\(\\rightarrow Y\\) \\(\\rightarrow Z \\rightarrow Y\\)), whereas natural\nindirect effect measures effect paths involving mediator\n(\\(\\rightarrow M \\rightarrow Y\\) \\(\\rightarrow Z \\rightarrow M \\rightarrow Y\\)). sum natural direct indirect effects equals average\ntreatment effect \\(\\mathbb{E}_c(Y_1-Y_0)\\), effect decomposition \nappealing. Unfortunately, natural direct indirect effects \ngenerally identified presence intermediate confounder affected\ntreatment.circumvent issue, (???) define direct indirect\neffects using stochastic interventions mediator, following strategy\npreviously outlined (???) (???), among\nothers. Let \\(G_a\\) denote random draw conditional distribution \n\\(M_a\\) conditional \\(W\\). Consider effect \\(\\) \\(Y\\) defined \ndifference expected outcome hypothetical worlds \\((,M) = (', G_{'})\\) versus \\((,M) = (^{\\star}, G_{^{\\star}})\\) probability one, \nmay decomposed direct indirect effects follows\n\\[\\begin{equation*}\n\\mathbb{E}_c(Y_{', G_{'}} - Y_{^{\\star}, G_{^{\\star}}}) =\n  \\underbrace{\\mathbb{E}_c(Y_{', G_{'}} - Y_{',\n    G_{^{\\star}}})}_{\\text{Indirect effect ($M$)}} +\n  \\underbrace{\\mathbb{E}_c(Y_{', G_{^{\\star}}} - Y_{^{\\star},\n      G_{^{\\star}}})}_{\\text{Direct effect ($M$)}}.\n\\end{equation*}\\]\nLike natural direct effect, interventional direct effect measures \neffects paths involving mediator. Likewise, interventional\nindirect effect measures effect paths involving mediator. Note,\nhowever, natural interventional mediation effects different\ninterpretations. , interventional indirect effect measures effect\nfixing exposure \\('\\) setting mediator random draw\n\\(G_{^{\\star}}\\) exposure \\('\\) versus random draw \\(G_{'}\\) \nexposure \\(^{\\star}\\), given covariates \\(W\\). clear \neffect decomposition, term \\(\\theta_c = \\mathbb{E}_c(Y_{', G_{^{\\star}}})\\)\nrequired estimation interventional direct indirect\neffects; thus, (???) focus estimation quantity.\nImportantly, shown \\(\\theta_c\\) identified statistical\nfunctional\n\\[\\begin{equation*}\n  \\theta = \\int b(', z, m, w) q(z \\mid ', w) p(m \\mid ^{\\star}, w)\n    p(w) d\\nu(w,z,m)\n\\end{equation*}\\]\nset standard identifiability conditions (???),\nreviewed (???).","code":""},{"path":"estimating-indirect-effects-with-r-packages.html","id":"efficient-estimation","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2.3 Efficient Estimation","text":"(???) define two efficient estimators interventional\n()direct effects. based one-step estimation targeted\nminimum loss (TML) estimation frameworks, respectively. Briefly, estimation\nstrategies proceed two stages, starting first constructing initial\nestimates nuisance parameters present EIF, proceeding \napply distinct bias-correction strategies second stages. \nestimation strategies require assumption behavior initial\nestimators nuisance parameters (specifically, lie Donsker\nclass); however, need assumption may avoided making use \ncross-validation fitting fo initial estimators. medoutcon R\npackage requires use cross-validation construction \ninitial estimates, resulting cross-fitted one-step cross-validated\nTML estimators (???; ???; ???).one-step estimator \\(\\hat{\\theta}_{\\text{os}}\\) constructed adding \nempirical mean EIF (evaluated initial estimates nuisance\nparameters) substitution estimator. constrast, TML estimator\n\\(\\hat{\\theta}_{\\text{tmle}}\\) updates components substitution\nestimator via logistic tilting models formulated ensure relevant score\nequations appearing EIF (approximately) solved. estimators\nasymptotically equivalent, TML estimators shown exhibit\nsuperior finite-sample performance, making potentially reliable \none-step estimators. exact form EIF well \none-step TML estimators, consult (???).","code":""},{"path":"estimating-indirect-effects-with-r-packages.html","id":"data-analysis-example","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2.4 Data Analysis Example","text":"","code":""},{"path":"estimating-indirect-effects-with-r-packages.html","id":"setting-up-the-data-example","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2.4.1 Setting up the data example","text":"Now, ’ll take look estimate interventional direct indirect\neffects using simulated data example. (???) illustrate \nuse estimators effects application seek \nelucidate mechanisms behind unintended harmful effects housing\nintervention adolescent girls’ risk behavior.First, let’s load required packages set seed simulation.Next, ’ll generate simple simulated dataset. function\nmake_example_data, defined , generates three binary baseline covariates\n\\(W = (W_1, W_2, W_3)\\), binary exposure variable \\(\\), single binary mediateor\n\\(M\\) intermediate confounder \\(Z\\) affects mediator \\(M\\) \naffected exposure \\(\\), , finally, binary outcome \\(Y\\) \nfunction \\((W, , Z, M)\\).Now, let’s take quick look simulated data:noted , covariates dataset binary; however, note \nneed case using methodology — particular, \ncurrent limitation intermediate confounder \\(Z\\) must binary \nusing implemented TML estimator ()direct effects.Using dataset, ’ll proceed estimate interventional ()direct\neffects. order , ’ll need estimate several nuisance parameters,\nincluding exposure mechanism \\(g(\\mid W)\\), re-parameterized exposure\nmechanism conditions mediators \\(h(\\mid M, W)\\), outcome\nmechanism \\(b(Y \\mid M, Z, , W)\\), two variants intermediate\nconfounding mechanism \\(q(Z \\mid , W)\\) \\(r(Z \\mid M, , W)\\). order \nestimate nuisance parameters flexibly, ’ll rely data adaptive\nregression strategies order avoid potential (parametric) model\nmisspecification.","code":"\nlibrary(data.table)\nlibrary(medoutcon)\nlibrary(sl3)\nset.seed(75681)\nn_obs <- 500\n# produces a simple data set based on ca causal model with mediation\nmake_example_data <- function(n_obs = 1000) {\n  ## baseline covariates\n  w_1 <- rbinom(n_obs, 1, prob = 0.6)\n  w_2 <- rbinom(n_obs, 1, prob = 0.3)\n  w_3 <- rbinom(n_obs, 1, prob = pmin(0.2 + (w_1 + w_2) / 3, 1))\n  w <- cbind(w_1, w_2, w_3)\n  w_names <- paste(\"W\", seq_len(ncol(w)), sep = \"_\")\n\n  ## exposure\n  a <- as.numeric(rbinom(n_obs, 1, plogis(rowSums(w) - 2)))\n\n  ## mediator-outcome confounder affected by treatment\n  z <- rbinom(n_obs, 1, plogis(rowMeans(-log(2) + w - a) + 0.2))\n\n  ## mediator -- could be multivariate\n  m <- rbinom(n_obs, 1, plogis(rowSums(log(3) * w[, -3] + a - z)))\n  m_names <- \"M\"\n\n  ## outcome\n  y <- rbinom(n_obs, 1, plogis(1 / (rowSums(w) - z + a + m)))\n\n  ## construct output\n  dat <- as.data.table(cbind(w = w, a = a, z = z, m = m, y = y))\n  setnames(dat, c(w_names, \"A\", \"Z\", m_names, \"Y\"))\n  return(dat)\n}\n\n# set seed and simulate example data\nexample_data <- make_example_data(n_obs)\nw_names <- stringr::str_subset(colnames(example_data), \"W\")\nm_names <- stringr::str_subset(colnames(example_data), \"M\")\n# quick look at the data\nhead(example_data)"},{"path":"estimating-indirect-effects-with-r-packages.html","id":"ensemble-learning-of-nuisance-functions","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2.4.2 Ensemble learning of nuisance functions","text":"’d like rely flexible, data adaptive regression strategies \nestimating nuisance parameters \\((g, h, b, q, r)\\), require \nmethod choosing among combining wide variety available regression\nstrategies. , recommend use Super Learner algorithm \nensemble machine learning (van der Laan, Polley, Hubbard 2007). recently developed sl3 R\npackage (???) provides unified interface\ndeploying wide variety machine learning algorithms (simply called\nlearners sl3 nomenclature) well constructing Super Learner\nensemble models learners. complete guide using sl3 R\npackage, consider consulting https://tlverse.org/sl3, https://tlverse.org\n(https://github.com/tlverse) tlverse ecosystem, sl3 \nintegral part.construct ensemble learner using handful popular machine learning\nalgorithms, ’ll first instantiate variants learners appropriate\nclasses algorithm, create Super Learner ensemble via \nLrnr_sl class. , demonstrate construction ensemble learner\nbased modeling library including intercept model, main-terms GLM,\n\\(\\ell_1\\)-penalized Lasso regression, elastic net regression equally\nweights \\(\\ell_1\\) \\(\\ell_2\\) penalties, random forests (ranger), \nhighly adaptive lasso (HAL):recommend use Super Learner ensemble model like one\nconstructed practice, library computationally\nintensive examples. reduce computation time, construct simpler\nlibrary, using subset learning algorithms:set ensemble learner, ’re now ready estimate \ninterventional effects using efficient estimators exposed medoutcon\npackage.","code":"\n# instantiate learners\nmean_lrnr <- Lrnr_mean$new()\nfglm_lrnr <- Lrnr_glm_fast$new(family = binomial())\nlasso_lrnr <- Lrnr_glmnet$new(alpha = 1, family = \"binomial\", nfolds = 3)\nenet_lrnr <- Lrnr_glmnet$new(alpha = 0.5, family = \"binomial\", nfolds = 3)\nrf_lrnr <- Lrnr_ranger$new(num.trees = 200)\n\n# for HAL, use linear probability formulation, with bounding in unit interval\nhal_gaussian_lrnr <- Lrnr_hal9001$new(\n  family = \"gaussian\",\n  fit_control = list(\n    max_degree = 3,\n    n_folds = 3,\n    use_min = TRUE,\n    type.measure = \"mse\"\n  )\n)\nbound_lrnr <- Lrnr_bound$new(bound = 1e-6)\nhal_bounded_lrnr <- Pipeline$new(hal_gaussian_lrnr, bound_lrnr)\n\n# create learner library and instantiate super learner ensemble\nlrnr_lib <- Stack$new(\n  mean_lrnr, fglm_lrnr, enet_lrnr, lasso_lrnr,\n  rf_lrnr, hal_bounded_lrnr\n)\nsl_lrnr <- Lrnr_sl$new(learners = lrnr_lib, metalearner = Lrnr_nnls$new())\n# create simpler learner library and instantiate super learner ensemble\nlrnr_lib <- Stack$new(mean_lrnr, fglm_lrnr, lasso_lrnr, rf_lrnr)\nsl_lrnr <- Lrnr_sl$new(learners = lrnr_lib, metalearner = Lrnr_nnls$new())"},{"path":"estimating-indirect-effects-with-r-packages.html","id":"estimating-the-direct-effect-1","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2.4.3 Estimating the direct effect","text":"’re now ready estimate interventional direct effect. direct effect\ncomputed contrast interventions \\((' = 1, ^{\\star} = 0)\\)\n\\((' = 0, ^{\\star} = 0)\\). particular, efficient estimators \ninterventional direct effect proceed constructing estimators\n\\(\\hat{\\theta}(' = 1, ^{\\star} = 0)\\) \\(\\hat{\\theta}(' = 0, ^{\\star} = 0)\\).\n, efficient estimator direct effect available application\ndelta method, , \\(\\hat{\\theta}^{\\text{DE}} = \\hat{\\theta}(' = 1, ^{\\star} = 0) - \\hat{\\theta}(' = 0, ^{\\star} = 0)\\).\nApplying principle EIF estimates, one can derive variance\nestimates construct asymptotically correct Wald-style confidence intervals\n\\(\\hat{\\theta}^{\\text{DE}}\\).medoutcon package makes estimation task quite simple, single\ncall eponymous medoutcon function required. demonstrated ,\nneed feed component observed data \\(O = (W, , Z, M, Y)\\)\n(\\(W\\) \\(M\\) can multivariate), specify effect type, \nestimator. Additionally, nuisance parameter may specify separate\nregression function — examples , use simpler Super Learner\nensemble constructed fitting nuisance function, need \ncase (.e., different estimators may used nuisance function).First, examine one-step estimator interventional direct effect.\nRecall one-step estimator constructed adding mean EIF\n(evaluated initial estimates nuisance parameters) substitution\nestimator. noted , done separately two contrasts\n\\((' = 0, ^{\\star} = 0)\\) \\((' = 1, ^{\\star} = 0)\\). Thus, one-step\nestimator direct effect constructed application delta\nmethod one-step estimators (EIFs) contrasts.Next, let’s compare one-step estimate TML estimate. Analogous \ncase one-step estimator, TML estimator can evaluated via single\ncall medoutcon function:, recall TML\nestimator generally exhibits better finite-sample performance one-step\nestimator (van der Laan Rose 2011, 2018), TML estimate likely \nreliable modest (realistic) sample sizes.","code":"\n# compute one-step estimate of the interventional direct effect\nos_de <- medoutcon(\n  W = example_data[, ..w_names],\n  A = example_data$A,\n  Z = example_data$Z,\n  M = example_data[, ..m_names],\n  Y = example_data$Y,\n  g_learners = sl_lrnr,\n  h_learners = sl_lrnr,\n  b_learners = sl_lrnr,\n  q_learners = sl_lrnr,\n  r_learners = sl_lrnr,\n  effect = \"direct\",\n  estimator = \"onestep\",\n  estimator_args = list(cv_folds = 2)\n)\nsummary(os_de)\n# compute targeted minimum loss estimate of the interventional direct effect\ntmle_de <- medoutcon(\n  W = example_data[, ..w_names],\n  A = example_data$A,\n  Z = example_data$Z,\n  M = example_data[, ..m_names],\n  Y = example_data$Y,\n  g_learners = sl_lrnr,\n  h_learners = sl_lrnr,\n  b_learners = sl_lrnr,\n  q_learners = sl_lrnr,\n  r_learners = sl_lrnr,\n  effect = \"direct\",\n  estimator = \"tmle\",\n  estimator_args = list(cv_folds = 2, max_iter = 5)\n)\nsummary(tmle_de)"},{"path":"estimating-indirect-effects-with-r-packages.html","id":"estimating-the-indirect-effect","chapter":"7 Estimating (in)direct effects with R packages","heading":"7.2.4.4 Estimating the indirect effect","text":"Estimation interventional indirect effect proceeds similarly \nstrategy discussed corresponding direct effect. efficient\nestimator can computed contrast interventions \\((' = 1, ^{\\star} = 0)\\) \\((' = 1, ^{\\star} = 1)\\). Specifically, efficient\nestimators interventional indirect effect proceed constructing\nestimators \\(\\hat{\\theta}(' = 1, ^{\\star} = 0)\\) \\(\\hat{\\theta}(' = 1, ^{\\star} = 1)\\). , application delta method yields efficient\nestimator indirect effect, , \\(\\hat{\\theta}^{\\text{IE}} = \\hat{\\theta}(' = 1, ^{\\star} = 0) - \\hat{\\theta}(' = 1, ^{\\star} = 1)\\). \nprinciple may applied EIF estimates derive variance estimates\nconstruct asymptotically correct Wald-style confidence intervals \n\\(\\hat{\\theta}^{\\text{IE}}\\).Now, examine one-step estimator interventional indirect effect.\none-step estimator constructed adding mean EIF\n(evaluated initial estimates nuisance parameters) substitution\nestimator. noted , done separately two contrasts\n\\((' = 1, ^{\\star} = 1)\\) \\((' = 1, ^{\\star} = 0)\\). Thus, one-step\nestimator indirect effect constructed application delta\nmethod one-step estimators (EIFs) contrasts., let’s compare one-step estimate TML estimate. Analogous\ncase one-step estimator, TML estimator can evaluated via \nsingle call medoutcon function, demonstrated belowAs , TML estimator provides better finite-sample performance \none-step estimator, may preferred example.","code":"\n# compute one-step estimate of the interventional indirect effect\nos_ie <- medoutcon(\n  W = example_data[, ..w_names],\n  A = example_data$A,\n  Z = example_data$Z,\n  M = example_data[, ..m_names],\n  Y = example_data$Y,\n  g_learners = sl_lrnr,\n  h_learners = sl_lrnr,\n  b_learners = sl_lrnr,\n  q_learners = sl_lrnr,\n  r_learners = sl_lrnr,\n  effect = \"indirect\",\n  estimator = \"onestep\"\n)\nsummary(os_ie)\n# compute targeted minimum loss estimate of the interventional indirect effect\ntmle_ie <- medoutcon(\n  W = example_data[, ..w_names],\n  A = example_data$A,\n  Z = example_data$Z,\n  M = example_data[, ..m_names],\n  Y = example_data$Y,\n  g_learners = sl_lrnr,\n  h_learners = sl_lrnr,\n  b_learners = sl_lrnr,\n  q_learners = sl_lrnr,\n  r_learners = sl_lrnr,\n  effect = \"indirect\",\n  estimator = \"tmle\"\n)\nsummary(tmle_ie)"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"Dı́az, Iván, Nima S Hejazi. 2020. “Causal Mediation Analysis Stochastic Interventions.” Journal Royal Statistical Society: Series B (Statistical Methodology) 82 (3): 661–83.Hejazi, Nima S, Kara E Rudolph, Mark J van der Laan, Iván Dı́az. 2020. “Nonparametric Causal Mediation Analysis Stochastic Interventional () Direct Effects.” arXiv Preprint arXiv:2009.06203.Kennedy, Edward H. 2018. “Nonparametric Causal Effects Based Incremental Propensity Score Interventions.” Journal American Statistical Association, nos. just-accepted.Rudolph, Kara, Ivan Diaz, Nima Hejazi, Mark van der Laan, Sean Luo, Matisyahu Shulman, Aimee Campbell, John Rotrosen, Edward Nunes. 2020. “Explaining Differential Effects Medication Opioid Use Disorder Using Novel Approach Incorporating Mediating Variables.” Addiction.van der Laan, Mark J, Eric C Polley, Alan E Hubbard. 2007. “Super Learner.” Statistical Applications Genetics Molecular Biology 6 (1).van der Laan, Mark J, Sherri Rose. 2011. Targeted Learning: Causal Inference Observational Experimental Data. Springer Science & Business Media.———. 2018. Targeted Learning Data Science: Causal Inference Complex Longitudinal Studies. Springer Science & Business Media.","code":""}]
